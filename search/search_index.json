{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Relax A compiled programming language, implemented entirely in AHK You might notice that the name is a bit ironic, since writing this in AHK gave me absolutely 0 chances to just relax . Note Relax generates 64 bit machine code, and depends on certain features that only exist on 64 bit processors. This means that there is no 32 bit support. I have no plans for adding 32 bit support, considering that 32 bit machine code is actually much more complex, and would need lots of special cases compared to 64 bit code. FAQ Q: What the fuck, why, dear god, why?! A: \u00af\\ (\u30c4) /\u00af (see \"Why I Did This\") Q: Wait, so this is an actual compiler? A: Yes, this script takes source code as input, tokenizes it, parses the tokens, optimizes the code a little bit, generates machine code for the parsed/optimized code, and finally builds a .exe file holding the compiled code. All without any outside tools. Every step is personally written by me. (Which probably isn't a good thing, but hey, I'm still proud of it) For more info, see how it all works How to use it See this page for the different ways Relax can be used. How to do most of the work: (I recommend you follow these in the order 1-2-3 if you already know a C-like language, and 2-1-3 otherwise) For a quick(-ish) rundown of the syntax, and some quirks, see the basic syntax page . For a tutorial sort of thing, see the tutorial page . For a full writeup of the syntax, see the full syntax page . How it works I wanted the header for this on this page, but it's long enough that you'll need to go to this page to read that. Why I did this I feel like I need to defend myself here, mostly because I know it's 100% insane to use AHK for a project like this. AHK was the first language I ever really mastered, and I got used to how everything works, and all of the quirks. Because of this, when I decided I wanted to write a toy language, I didn't think of doing it in a \"real\" language since I already had a language that you can easily (and quickly) prototype things in right in front of me. As for why I'd want to write a language, it's just an interesting topic. I seriously recommend checking out the basics of language design, it's a field which I didn't even know existed until I stumbled on this ungodly useful (and high quality) free book and started reading. Try your hand at a quick brainfuck interpreter, and if you like the concept, give that book I mentioned a try. Just make sure that your first project is not a full on compiled language. Working on this language has been a rollercoaster, and I blame 100% of that on my ambitions being way too high. If you decide to write your own language, do not push yourself to work on it constantly. I did that, and now I'm burnt out enough to stop writing in AHK entirely. Also, embrace things like LLVM, and pre-made linkers. At some point in this project I decided I wanted to do it all on my own. Which was an absolutely terrible idea. Reinventing every part in the car instead of just a wheel will teach you a lot, but its not fun. Not to mention LLVM can generate much better code than you will manually. Credits @SALZKARTOFFEEEL#9805 On Discord, for listening to all of my complaints while I worked on this. @mordecai#2885 On Discord, for catching some of the numerous mistakes I made in these docs. rommmcek On the AHK forums, for finding some kind of bug which I haven't quite figured out yet.","title":"Relax"},{"location":"#relax","text":"A compiled programming language, implemented entirely in AHK You might notice that the name is a bit ironic, since writing this in AHK gave me absolutely 0 chances to just relax .","title":"Relax"},{"location":"#note","text":"Relax generates 64 bit machine code, and depends on certain features that only exist on 64 bit processors. This means that there is no 32 bit support. I have no plans for adding 32 bit support, considering that 32 bit machine code is actually much more complex, and would need lots of special cases compared to 64 bit code.","title":"Note"},{"location":"#faq","text":"","title":"FAQ"},{"location":"#q-what-the-fuck-why-dear-god-why","text":"A: \u00af\\ (\u30c4) /\u00af (see \"Why I Did This\")","title":"Q: What the fuck, why, dear god, why?!"},{"location":"#q-wait-so-this-is-an-actual-compiler","text":"A: Yes, this script takes source code as input, tokenizes it, parses the tokens, optimizes the code a little bit, generates machine code for the parsed/optimized code, and finally builds a .exe file holding the compiled code. All without any outside tools. Every step is personally written by me. (Which probably isn't a good thing, but hey, I'm still proud of it) For more info, see how it all works","title":"Q: Wait, so this is an actual compiler?"},{"location":"#how-to-use-it","text":"See this page for the different ways Relax can be used.","title":"How to use it"},{"location":"#how-to-do-most-of-the-work","text":"(I recommend you follow these in the order 1-2-3 if you already know a C-like language, and 2-1-3 otherwise) For a quick(-ish) rundown of the syntax, and some quirks, see the basic syntax page . For a tutorial sort of thing, see the tutorial page . For a full writeup of the syntax, see the full syntax page .","title":"How to do most of the work:"},{"location":"#how-it-works","text":"I wanted the header for this on this page, but it's long enough that you'll need to go to this page to read that.","title":"How it works"},{"location":"#why-i-did-this","text":"I feel like I need to defend myself here, mostly because I know it's 100% insane to use AHK for a project like this. AHK was the first language I ever really mastered, and I got used to how everything works, and all of the quirks. Because of this, when I decided I wanted to write a toy language, I didn't think of doing it in a \"real\" language since I already had a language that you can easily (and quickly) prototype things in right in front of me. As for why I'd want to write a language, it's just an interesting topic. I seriously recommend checking out the basics of language design, it's a field which I didn't even know existed until I stumbled on this ungodly useful (and high quality) free book and started reading. Try your hand at a quick brainfuck interpreter, and if you like the concept, give that book I mentioned a try. Just make sure that your first project is not a full on compiled language. Working on this language has been a rollercoaster, and I blame 100% of that on my ambitions being way too high. If you decide to write your own language, do not push yourself to work on it constantly. I did that, and now I'm burnt out enough to stop writing in AHK entirely. Also, embrace things like LLVM, and pre-made linkers. At some point in this project I decided I wanted to do it all on my own. Which was an absolutely terrible idea. Reinventing every part in the car instead of just a wheel will teach you a lot, but its not fun. Not to mention LLVM can generate much better code than you will manually.","title":"Why I did this"},{"location":"#credits","text":"@SALZKARTOFFEEEL#9805 On Discord, for listening to all of my complaints while I worked on this. @mordecai#2885 On Discord, for catching some of the numerous mistakes I made in these docs. rommmcek On the AHK forums, for finding some kind of bug which I haven't quite figured out yet.","title":"Credits"},{"location":"basic-syntax/","text":"The basic syntax It's pretty much C, but with minor changes. Although many things are borrowed from C, this is not a C compiler, and does not have all the features C has. Mainly, it's missing structures, and arrays. Types Type names are changed to be more concise, and shorter. Integer types: Precision C Name (LanguageName) Name 8 bits char i8 16 bits short i16 32 bits long i32 64 bits long long / __int64 i64 Floating point types: Precision C Name (LanguageName) Name 32 bits float f32 64 bits double f64 Additionally, there is the void type, which is exactly what you'd expect it to be: a 64 bit integer (I can't remember why I made it this way). Of course, there are also pointer types, which follow C syntax of TypeName* . Pointer-pointer types are not implemented. General Things String literals are supported, and are replaced with an i8* to the given string. This i8* will point into the stack, so DO NOT try to free this memory. You can alter it, but changing the size of it, or overrunning its length is VERY VERY BAD . If a function does not have a return in it, a return 0 is implicitly added. The magic entry-point function is named Main , and receives a i64 parameter containing the number of command line arguments, along with a void* which is actually an array of i16* pointers to the individual command line arguments (Just like how in C you have ArgC and ArgV ) Main should have a return type of i32 , as the return value will be given to the Windows API ExitProcess function as the program's exit code. Now's a good time to note: If you prefix the name of a variable or function with __ , you are very likely to break something internal. The __ prefix is reserved, and I will be very unhappy with you if you use it. Assignment operators Most assignment operators act as you'd expect, except for *= . Since I really like the C syntax for pointers, but hate the C syntax to assign the value a pointer points to, the *= is used for assignment of a memory address to a new value. For example (PointerToAString + 90) *= 'H' would set the character at PointerToAString + 90 to be H . Since *= is taken, /= is not implemented to prevent confusion over only one of the two working like normal, += and -= are the only shorthand assignment operators. Additionally, since floating point number support is half-baked (at best), += and -= are not implemented for floating point numbers. So, that leaves us with the 4 assignment operators: := , *= , += , -= . Binary operators Another minor change is with the logical operators && and || . I can't think of a good way to generate code which will have these operators short-circuit, so they don't. Additionally, some operators are not implemented for floating point operands. This is mostly because I do floating point math with the (actually older than me) x87 FPU, and can't figure out the FPU instructions needed for some operators. These operators are: % (Modulo), && , and || . (You'll get an error message when you try to use them on floating point operands) Bitwise operators are allowed on all data types, simply because I think it's dumb that they aren't in some languages. If you want to mangle the floating point number format, go for it. The full list of binary operators: + , - , * , / , % (Modulo), = (regular equality, there's no == ), != , < , <= , > , >= , && , || , & , | , ^ Yes, I know there's no bit-shifts. If anyone besides me ever uses this language and wants bit-shifts, I'll implement them. Casting Casting between types is usually implicit, but if you want to explicitly cast between two obviously incompatible types, the As operator does it. The format is Operand As TypeName , just be careful with Operand , since As will take the closest thing on its left, so 1 + 2 As f32 would be parsed as 1 + (2 As f32) . This funky word operator is because I honestly fear for my mental and physical health if I have to modify the expression parser to handle C style casting. Unary operators Unary operators also have some odd bits, mostly because I forgot to implement how they work with different types. (All data types are treated like integers with unary operators) So make sure not to have something like -AFloatingPointNumber , because that'll cause some problems. 0 - AFloatingPointNumber works fine though. Oh, and AFloatingPointNumber with ++ or -- will also cause some problems. & Functions as you'd expect in C, same with * (which requires a pointer type as the operand). ++Variable and Variable++ also function as you'd expect, I made sure. ++PointerVariable is also implemented to increment PointerVariable by however big the value it points to is, ex: i64 SomeNumber := 99 i64* PointerVariable := &SomeNumber ++PointerVariable Would increment PointerVariable by 8 Array-access Array accesses are really just pointer syntax sugar, but god do they make things easier. Pointer[Index] will do the same operation as *(Pointer + (SizeOfPointedToType(Pointer) * Index)) , except in ~3 instructions. Instead of evaluating a bunch of expressions manually, the addition and multiplication steps are both done by the CPU directly, which should be a speed up. The actual instructions are lea rax, [PointerRegister + IndexRegister * TYPESIZE] mov ResultRegister, 0 mov ResultRegister, TYPENAME PTR [rax] Where TYPESIZE is the size of each element in the array (1, 2, 4, or 8 bytes), and TYPENAME is the name of the type of each element. The mov ResultRegister, 0 is because depending on TYPENAME , the mov ResultRegister, [rax] might only move 1/2/4 bytes into the 8 byte register, which could leave garbage data in the top few bytes. But by zeroing the result register, we clear any garbage. For example, mov rcx, BYTE PTR [rax] would only set the low 1 byte of rcx , leaving the top 7 bytes unchanged. What next? For a tutorial sort of thing, see the tutorial page . For a full writeup of the syntax, see the full syntax page .","title":"Basic syntax"},{"location":"basic-syntax/#the-basic-syntax","text":"It's pretty much C, but with minor changes. Although many things are borrowed from C, this is not a C compiler, and does not have all the features C has. Mainly, it's missing structures, and arrays.","title":"The basic syntax"},{"location":"basic-syntax/#types","text":"Type names are changed to be more concise, and shorter. Integer types: Precision C Name (LanguageName) Name 8 bits char i8 16 bits short i16 32 bits long i32 64 bits long long / __int64 i64 Floating point types: Precision C Name (LanguageName) Name 32 bits float f32 64 bits double f64 Additionally, there is the void type, which is exactly what you'd expect it to be: a 64 bit integer (I can't remember why I made it this way). Of course, there are also pointer types, which follow C syntax of TypeName* . Pointer-pointer types are not implemented.","title":"Types"},{"location":"basic-syntax/#general-things","text":"String literals are supported, and are replaced with an i8* to the given string. This i8* will point into the stack, so DO NOT try to free this memory. You can alter it, but changing the size of it, or overrunning its length is VERY VERY BAD . If a function does not have a return in it, a return 0 is implicitly added. The magic entry-point function is named Main , and receives a i64 parameter containing the number of command line arguments, along with a void* which is actually an array of i16* pointers to the individual command line arguments (Just like how in C you have ArgC and ArgV ) Main should have a return type of i32 , as the return value will be given to the Windows API ExitProcess function as the program's exit code. Now's a good time to note: If you prefix the name of a variable or function with __ , you are very likely to break something internal. The __ prefix is reserved, and I will be very unhappy with you if you use it.","title":"General Things"},{"location":"basic-syntax/#assignment-operators","text":"Most assignment operators act as you'd expect, except for *= . Since I really like the C syntax for pointers, but hate the C syntax to assign the value a pointer points to, the *= is used for assignment of a memory address to a new value. For example (PointerToAString + 90) *= 'H' would set the character at PointerToAString + 90 to be H . Since *= is taken, /= is not implemented to prevent confusion over only one of the two working like normal, += and -= are the only shorthand assignment operators. Additionally, since floating point number support is half-baked (at best), += and -= are not implemented for floating point numbers. So, that leaves us with the 4 assignment operators: := , *= , += , -= .","title":"Assignment operators"},{"location":"basic-syntax/#binary-operators","text":"Another minor change is with the logical operators && and || . I can't think of a good way to generate code which will have these operators short-circuit, so they don't. Additionally, some operators are not implemented for floating point operands. This is mostly because I do floating point math with the (actually older than me) x87 FPU, and can't figure out the FPU instructions needed for some operators. These operators are: % (Modulo), && , and || . (You'll get an error message when you try to use them on floating point operands) Bitwise operators are allowed on all data types, simply because I think it's dumb that they aren't in some languages. If you want to mangle the floating point number format, go for it. The full list of binary operators: + , - , * , / , % (Modulo), = (regular equality, there's no == ), != , < , <= , > , >= , && , || , & , | , ^ Yes, I know there's no bit-shifts. If anyone besides me ever uses this language and wants bit-shifts, I'll implement them.","title":"Binary operators"},{"location":"basic-syntax/#casting","text":"Casting between types is usually implicit, but if you want to explicitly cast between two obviously incompatible types, the As operator does it. The format is Operand As TypeName , just be careful with Operand , since As will take the closest thing on its left, so 1 + 2 As f32 would be parsed as 1 + (2 As f32) . This funky word operator is because I honestly fear for my mental and physical health if I have to modify the expression parser to handle C style casting.","title":"Casting"},{"location":"basic-syntax/#unary-operators","text":"Unary operators also have some odd bits, mostly because I forgot to implement how they work with different types. (All data types are treated like integers with unary operators) So make sure not to have something like -AFloatingPointNumber , because that'll cause some problems. 0 - AFloatingPointNumber works fine though. Oh, and AFloatingPointNumber with ++ or -- will also cause some problems. & Functions as you'd expect in C, same with * (which requires a pointer type as the operand). ++Variable and Variable++ also function as you'd expect, I made sure. ++PointerVariable is also implemented to increment PointerVariable by however big the value it points to is, ex: i64 SomeNumber := 99 i64* PointerVariable := &SomeNumber ++PointerVariable Would increment PointerVariable by 8","title":"Unary operators"},{"location":"basic-syntax/#array-access","text":"Array accesses are really just pointer syntax sugar, but god do they make things easier. Pointer[Index] will do the same operation as *(Pointer + (SizeOfPointedToType(Pointer) * Index)) , except in ~3 instructions. Instead of evaluating a bunch of expressions manually, the addition and multiplication steps are both done by the CPU directly, which should be a speed up. The actual instructions are lea rax, [PointerRegister + IndexRegister * TYPESIZE] mov ResultRegister, 0 mov ResultRegister, TYPENAME PTR [rax] Where TYPESIZE is the size of each element in the array (1, 2, 4, or 8 bytes), and TYPENAME is the name of the type of each element. The mov ResultRegister, 0 is because depending on TYPENAME , the mov ResultRegister, [rax] might only move 1/2/4 bytes into the 8 byte register, which could leave garbage data in the top few bytes. But by zeroing the result register, we clear any garbage. For example, mov rcx, BYTE PTR [rax] would only set the low 1 byte of rcx , leaving the top 7 bytes unchanged.","title":"Array-access"},{"location":"basic-syntax/#what-next","text":"For a tutorial sort of thing, see the tutorial page . For a full writeup of the syntax, see the full syntax page .","title":"What next?"},{"location":"basic-tutorial/","text":"Good luck. Let's be honest here, nobody's going to use this language at all, let alone people who are new to programming. Either way, I've got time to waste. Get ready for a bad intro to low-level compiled languages. Ignore that part right above here In Relax, all variables and values have 'types'. This means that a variable can only hold one kind of thing, and that variables will only ever hold one kind of thing. Additionally, you can only use two variables when they have compatible types, so you can't do something like \"This Is My String Of Text\" * 9.2 . The way you decide what type a variable has is by 'declaring' the variable to be a certain type. In Relax you declare a variable to be a certain type by typing a 'type name' along with the variable name, for example: i64 MyVariable f32 MyOtherVariable Additionally, you can include an 'initial value' after the declaration, like i64 MyVariable := 99 + 20 i32 MyOtherVariable := 10.5 Variables only need to be declared once, however, you can change a variable's value as much as you like. Great, now that we've got that down, we can move on to functions . A function is a way to wrap a bunch of lines of code which accomplish a task into a single thing . For example: You might have a function to print some text to the screen. A function has a few components: A name, which is used when 'calling' the function (calling = running it) A return type, which is what kind of value the function returns (returns = gives back to whatever is running the function) A list of parameters, and parameter types, which are values which are passed to the function to change what it does (passed = given to the function before it runs) The body of the function, which is simply lines of code that are run when the function is called. So, if we want to write a function to add two numbers, we'd start with the name and return type, along with a special word to signal we are defining a function. Which leaves us with the format: define ReturnType Name Now we'll replace ReturnType with the standard number type, which is i64 , and Name with the name of the function (we will call it Add ) define i64 Add Great, now we're getting there. Next we need a list of parameters. Remember that parameters are values given to a function, which change what it does. In this case, the parameters should be the two numbers to add, since an Add function which only does the math for 1 + 1 isn't very useful. The format for parameters is: (TypeName ParameterName, TypeName ParameterName) Where you can have as many TypeName ParameterName combos as you'd like Since we want to take two numbers, we'll replace TypeName with i64 . Then, ParameterName is the name of a variable, which will be set to whatever value is passed to this function. So, each parameter name needs to be unique. We'll go with LeftNumber and RightNumber for the names here, which leaves us with: (i64 LeftNumber, i64 RightNumber) And then we stick that onto the code from earlier and get: define i64 Add(i64 LeftNumber, i64 RightNumber) Alright, to save myself some pain and suffering, I'm just going to finish the function and explain it define i64 Add(i64 LeftNumber, i64 RightNumber) { return LeftNumber + RightNumber } return will run the code to the right of it, and give the result back to whatever is using this function. LeftNumber + RightNumber will use the two parameters, and add them. God does this tutorial suck","title":"Basic tutorial"},{"location":"basic-tutorial/#good-luck","text":"Let's be honest here, nobody's going to use this language at all, let alone people who are new to programming. Either way, I've got time to waste. Get ready for a bad intro to low-level compiled languages.","title":"Good luck."},{"location":"basic-tutorial/#ignore-that-part-right-above-here","text":"In Relax, all variables and values have 'types'. This means that a variable can only hold one kind of thing, and that variables will only ever hold one kind of thing. Additionally, you can only use two variables when they have compatible types, so you can't do something like \"This Is My String Of Text\" * 9.2 . The way you decide what type a variable has is by 'declaring' the variable to be a certain type. In Relax you declare a variable to be a certain type by typing a 'type name' along with the variable name, for example: i64 MyVariable f32 MyOtherVariable Additionally, you can include an 'initial value' after the declaration, like i64 MyVariable := 99 + 20 i32 MyOtherVariable := 10.5 Variables only need to be declared once, however, you can change a variable's value as much as you like. Great, now that we've got that down, we can move on to functions . A function is a way to wrap a bunch of lines of code which accomplish a task into a single thing . For example: You might have a function to print some text to the screen. A function has a few components: A name, which is used when 'calling' the function (calling = running it) A return type, which is what kind of value the function returns (returns = gives back to whatever is running the function) A list of parameters, and parameter types, which are values which are passed to the function to change what it does (passed = given to the function before it runs) The body of the function, which is simply lines of code that are run when the function is called. So, if we want to write a function to add two numbers, we'd start with the name and return type, along with a special word to signal we are defining a function. Which leaves us with the format: define ReturnType Name Now we'll replace ReturnType with the standard number type, which is i64 , and Name with the name of the function (we will call it Add ) define i64 Add Great, now we're getting there. Next we need a list of parameters. Remember that parameters are values given to a function, which change what it does. In this case, the parameters should be the two numbers to add, since an Add function which only does the math for 1 + 1 isn't very useful. The format for parameters is: (TypeName ParameterName, TypeName ParameterName) Where you can have as many TypeName ParameterName combos as you'd like Since we want to take two numbers, we'll replace TypeName with i64 . Then, ParameterName is the name of a variable, which will be set to whatever value is passed to this function. So, each parameter name needs to be unique. We'll go with LeftNumber and RightNumber for the names here, which leaves us with: (i64 LeftNumber, i64 RightNumber) And then we stick that onto the code from earlier and get: define i64 Add(i64 LeftNumber, i64 RightNumber) Alright, to save myself some pain and suffering, I'm just going to finish the function and explain it define i64 Add(i64 LeftNumber, i64 RightNumber) { return LeftNumber + RightNumber } return will run the code to the right of it, and give the result back to whatever is using this function. LeftNumber + RightNumber will use the two parameters, and add them.","title":"Ignore that part right above here"},{"location":"basic-tutorial/#god-does-this-tutorial-suck","text":"","title":"God does this tutorial suck"},{"location":"changelog/","text":"Changelog Top of page = most recent. 1.0.0-alpha.29 Added Pointer-pointer types, allowing things like i64** or void******************* . (Maybe don't use that second one though) An array-access syntax for pointers which scales the index for you, so ArgV[Index] would be equal to *(ArgV + (8 * Index)) and ArrayOfI16s[Index] would be equal to *(ArrayOfI16s + (2 * Index)) Changed The ArgV parameter to Main to be of the type i16** . The version number Binary expressions with the operators || or && to result in i8 typed values. The String module to use the array access syntax when possible. The example programs to use the new ArgV type, and to use the array access syntax. Fixed Programs with 0 global variables generating broken output files. Most error messages not have any source code shown. Some error messages having the wrong code/not enough code highlighted. *= Only working with some types. Modules which Import each other crashing the compiler. Regular AHK exceptions causing the compiler to print \"Fatal error, bailing out.\" and exit without any context. Docs Changes Edited Basic Syntax to remove the mention of not having pointer-pointer types. Added an explanation of array accesses on the basic syntax page. Added the syntax for an array access on the full syntax page. Added an explanation of pointer-pointer types on the full syntax page. Added this page to act as a changelog 1.0.0-alpha.28 (And lower) None, the change log is new as of alpha.29 .","title":"Changelog"},{"location":"changelog/#changelog","text":"Top of page = most recent.","title":"Changelog"},{"location":"changelog/#100-alpha29","text":"","title":"1.0.0-alpha.29"},{"location":"changelog/#added","text":"Pointer-pointer types, allowing things like i64** or void******************* . (Maybe don't use that second one though) An array-access syntax for pointers which scales the index for you, so ArgV[Index] would be equal to *(ArgV + (8 * Index)) and ArrayOfI16s[Index] would be equal to *(ArrayOfI16s + (2 * Index))","title":"Added"},{"location":"changelog/#changed","text":"The ArgV parameter to Main to be of the type i16** . The version number Binary expressions with the operators || or && to result in i8 typed values. The String module to use the array access syntax when possible. The example programs to use the new ArgV type, and to use the array access syntax.","title":"Changed"},{"location":"changelog/#fixed","text":"Programs with 0 global variables generating broken output files. Most error messages not have any source code shown. Some error messages having the wrong code/not enough code highlighted. *= Only working with some types. Modules which Import each other crashing the compiler. Regular AHK exceptions causing the compiler to print \"Fatal error, bailing out.\" and exit without any context.","title":"Fixed"},{"location":"changelog/#docs-changes","text":"Edited Basic Syntax to remove the mention of not having pointer-pointer types. Added an explanation of array accesses on the basic syntax page. Added the syntax for an array access on the full syntax page. Added an explanation of pointer-pointer types on the full syntax page. Added this page to act as a changelog","title":"Docs Changes"},{"location":"changelog/#100-alpha28-and-lower","text":"None, the change log is new as of alpha.29 .","title":"1.0.0-alpha.28 (And lower)"},{"location":"compile-to-ahk/","text":"Compiling To AHK Relax supports compiling to AHK through a boilerplate function which is used as a linker+loader for the compiled code. All you need to do to compile to .ahk instead of .exe is change the [OutputFile] path given to Main to have the .ahk extension. The boilerplate The boilerplate function is used to: Set up an import table (which holds pointers to all imported functions) Set up a global table (which is the memory used for global variables) Populate the import table with all imported functions Allocate executable memory for the compiled code Link any references to the import table or global table while writing the compiled code into memory Get pointers to compiled functions (The boilerplate function also stores the offsets to each function) Free the compiled code on exit Additionally, \"caller\" functions are generated for each function inside of the given program, which follow the format FunctionName(ParameterList) { static pThisFunction := _CompiledCodeAddressOf(FunctionName) return DllCall(pThisFunction, ParameterTypeList + ParameterList, ReturnType) } Where: FunctionName is replaced with the name of the function as it is written in the source code ParameterList is a comma-separated list of the functions parameters (name only, as found in the source) ParameterTypeList + ParameterList is a list of ParameterType, ParameterName pairs, with ParameterType being an AHK DllCall type for the parameter's actual type. ReturnType is an AHK DllCall type for the function's return type. The template for the boilerplate function can be found in Compiler\\ToAHK.ahk . Note By default, the boilerplate function does not initialize global variables to their defaults. This is because if compiled code requires prior setup (like a call to AllocConsole ), the setup must be done before global defaults are set. To manually set global variables after any setup code is done, include a call to __RunTime__SetGlobals . It is not recommended to call __RunTime__CallMain , as it is the program entry point for .exe files, and automatically calls ExitProcess after the Main function returns.","title":"Compiling To AHK"},{"location":"compile-to-ahk/#compiling-to-ahk","text":"Relax supports compiling to AHK through a boilerplate function which is used as a linker+loader for the compiled code. All you need to do to compile to .ahk instead of .exe is change the [OutputFile] path given to Main to have the .ahk extension.","title":"Compiling To AHK"},{"location":"compile-to-ahk/#the-boilerplate","text":"The boilerplate function is used to: Set up an import table (which holds pointers to all imported functions) Set up a global table (which is the memory used for global variables) Populate the import table with all imported functions Allocate executable memory for the compiled code Link any references to the import table or global table while writing the compiled code into memory Get pointers to compiled functions (The boilerplate function also stores the offsets to each function) Free the compiled code on exit Additionally, \"caller\" functions are generated for each function inside of the given program, which follow the format FunctionName(ParameterList) { static pThisFunction := _CompiledCodeAddressOf(FunctionName) return DllCall(pThisFunction, ParameterTypeList + ParameterList, ReturnType) } Where: FunctionName is replaced with the name of the function as it is written in the source code ParameterList is a comma-separated list of the functions parameters (name only, as found in the source) ParameterTypeList + ParameterList is a list of ParameterType, ParameterName pairs, with ParameterType being an AHK DllCall type for the parameter's actual type. ReturnType is an AHK DllCall type for the function's return type. The template for the boilerplate function can be found in Compiler\\ToAHK.ahk .","title":"The boilerplate"},{"location":"compile-to-ahk/#note","text":"By default, the boilerplate function does not initialize global variables to their defaults. This is because if compiled code requires prior setup (like a call to AllocConsole ), the setup must be done before global defaults are set. To manually set global variables after any setup code is done, include a call to __RunTime__SetGlobals . It is not recommended to call __RunTime__CallMain , as it is the program entry point for .exe files, and automatically calls ExitProcess after the Main function returns.","title":"Note"},{"location":"dumb-errors/","text":"A list stupid errors Apparently this variable is undeclared, while I am declaring it OH MY GOD. I have been forgetting to check the conditions of if statements There's just flat out no code for it don't you just hate when you can't assign your typed variable with := ?","title":"Dumb errors"},{"location":"dumb-errors/#a-list-stupid-errors","text":"Apparently this variable is undeclared, while I am declaring it OH MY GOD. I have been forgetting to check the conditions of if statements There's just flat out no code for it don't you just hate when you can't assign your typed variable with := ?","title":"A list stupid errors"},{"location":"full-syntax/","text":"The full syntax description Program The compiler expects input code to be a \"program\", a program is defined as a list of the following statements: Import statements DllImport statements Define statements Global declarations Import Import statements follow the format: Import ModuleName Where ModuleName is the name of a built in module. The current list of built in modules is: Memory String Console DllImport DllImport statements follow the format: DllImport ReturnType FunctionName(ParameterTypeList) {DllFileName.dll, FunctionNameInsideDLL} ReturnType is the type that the function is expected to return. FunctionName is the name that the function will have internally, and is the name you use to call it. This name does not need to be the same as FunctionNameInsideDLL . ParameterTypeList is a list of comma-separated types , without any names, since the parameter names are not needed. DllFileName.dll is the name of the file which contains the given function. FunctionNameInsideDLL is the name of the function, as it is exported in from the DLL. Define Define statements follow the format: Define ReturnType FunctionName(ParameterList) { Body } ReturnType is the type that the function is expected to return. FunctionName is the name that the function will have, and is the name you use to call it. ParameterList is a list of comma-separated type name pairs. Body is a list of statements . Global Global declarations follow the same format as regular declarations . However, global declarations make variables that are program -wide, and can be used from any function. Additionally, global declarations run just before Main is called (and ArgC/ArgV are set), making them a suitable method to run setup code. Statements Statements follow multiple different formats, depending on the type of statement. Declarations Keyword statements Expression statements It is important to note that this 'statement' category does not include the program statements, which are not allowed inside of functions. All of the above statements are allowed inside of functions and other structures such as for loops or if statements . Declarations Declarations follow the format(s): TypeName VariableName TypeName VariableName := Value TypeName is the type that the variable will have. VariableName is the name the variable will have. := Value is an optional assignment to give the variable a default value. Variables that do not have a default value should be considered to have an undefined value until they are otherwise assigned. Keywords Keyword statements follow multiple different formats, depending on the keyword used. if/else if/else statements for loops break/continue statements return statements These are all of the statements implemented, there are no while loops. If If statements follow a single variable format, depending on the structure of the if statement: if (Condition) { Body } else if (OtherCondition) { Body } else { Body } if is the required keyword to start an if statement. (Condition) an expression which will be tested in order to decide if the next block will run or not. Body (in all places) is a list of statements(#statements) which will run if the prior condition resulted in a non-zero result. else if the required keyword to add another condition and body to the entire if statement. else the required keyword to add a final body to the if statement, which will only run when no other conditions are met. else if can be repeated any number of times, for any number of conditions. There can only be one else for each if statement. For For loops follow the format: for (Init, Condition, Step) { Body } Init , Condition , and Step are all expressions which run at different points. Body is a list of statements(#statements) which will run each iteration of the loop. Init can optionally be a declaration and is run before the loop first stats, and never again. Condition is checked before the loop runs an iteration, and if it is false, the loop will stop. Step is run after each iteration of the loop. Break-Continue Break and continue both follow the format: Break Continue With no extra code. The break and continue statements are only valid inside of for loops . Return Return statements follow the format: Return Value Value is any kind of expression , which will be returned to the caller. Value must evaluate to a type compatible to the return type of the current function . Expression-Statements Expression statements follow the format: Expression Expression is any kind of expression . If Expression does not call a function or set a variable, it will be eliminated by the compiler during dead-code elimination. Expression Expressions follow many formats, examples: A := B + C (2 - E) / 2.5 9999 + *(G) % H Any unquoted text inside an expression is treated as a variable. Quoted text is treated as an i8* typed value. Numbers are treated as the smallest possible type to hold them (ex: 58 would be an i8 , 9999 would be an i16 ) Operands of any given operator must be a someone-similar type (ex: 2.6 * SomePointer is invalid). Operators are evaluated according to precedence and associativity, which is defined in Constants.ahk . Some operators may not be implemented for a given type Some expressions may be used as booleans inside of for loops or if statements . This is done by checking if the expressions results in 0 or not. Additionally, there is the format: Something[SomethingElse] Where Something is an expression which results in a pointer-type, and SomethingElse results in an integer, which will be used as an index into Something . Operator list Binary Operators Category Name Precedence Associativity Operators in category Assignment 0 Right := , += , -= , *= Logic 1 Right && , || Equality 2 Left != , = Comparison 3 Right < , <= , > , >= Unused 4 Addition 5 Left + , - Division 6 Left / , * , % Bitwise 7 Left & , | , ^ Module 8 N/A : Unary Operators Operator Prefix/Postfix ++ Both -- Both ! Prefix ~ Prefix * Prefix & Prefix Types A type is simply a combination of a identifier, with any number of * s after it (each * increases the level of nested pointers) The base type names are i8 , i16 , i32 , i64 f32 , f64 void With pointer (and pointer-pointer) types for each, like: void* - Pointer to void i16** - Pointer to a pointer to an i16 i8* - Pointer to an i8 void***************** - Pointer to a pointer to a pointer to a pointer to a pointer to a pointer to a pointer.... you get it Names Names are simply combinations of characters and numbers. Names must start with a-z, but can contain numbers after the first letter.","title":"Full syntax"},{"location":"full-syntax/#the-full-syntax-description","text":"","title":"The full syntax description"},{"location":"full-syntax/#program","text":"The compiler expects input code to be a \"program\", a program is defined as a list of the following statements: Import statements DllImport statements Define statements Global declarations","title":"Program"},{"location":"full-syntax/#import","text":"Import statements follow the format: Import ModuleName Where ModuleName is the name of a built in module. The current list of built in modules is: Memory String Console","title":"Import"},{"location":"full-syntax/#dllimport","text":"DllImport statements follow the format: DllImport ReturnType FunctionName(ParameterTypeList) {DllFileName.dll, FunctionNameInsideDLL} ReturnType is the type that the function is expected to return. FunctionName is the name that the function will have internally, and is the name you use to call it. This name does not need to be the same as FunctionNameInsideDLL . ParameterTypeList is a list of comma-separated types , without any names, since the parameter names are not needed. DllFileName.dll is the name of the file which contains the given function. FunctionNameInsideDLL is the name of the function, as it is exported in from the DLL.","title":"DllImport"},{"location":"full-syntax/#define","text":"Define statements follow the format: Define ReturnType FunctionName(ParameterList) { Body } ReturnType is the type that the function is expected to return. FunctionName is the name that the function will have, and is the name you use to call it. ParameterList is a list of comma-separated type name pairs. Body is a list of statements .","title":"Define"},{"location":"full-syntax/#global","text":"Global declarations follow the same format as regular declarations . However, global declarations make variables that are program -wide, and can be used from any function. Additionally, global declarations run just before Main is called (and ArgC/ArgV are set), making them a suitable method to run setup code.","title":"Global"},{"location":"full-syntax/#statements","text":"Statements follow multiple different formats, depending on the type of statement. Declarations Keyword statements Expression statements It is important to note that this 'statement' category does not include the program statements, which are not allowed inside of functions. All of the above statements are allowed inside of functions and other structures such as for loops or if statements .","title":"Statements"},{"location":"full-syntax/#declarations","text":"Declarations follow the format(s): TypeName VariableName TypeName VariableName := Value TypeName is the type that the variable will have. VariableName is the name the variable will have. := Value is an optional assignment to give the variable a default value. Variables that do not have a default value should be considered to have an undefined value until they are otherwise assigned.","title":"Declarations"},{"location":"full-syntax/#keywords","text":"Keyword statements follow multiple different formats, depending on the keyword used. if/else if/else statements for loops break/continue statements return statements These are all of the statements implemented, there are no while loops.","title":"Keywords"},{"location":"full-syntax/#if","text":"If statements follow a single variable format, depending on the structure of the if statement: if (Condition) { Body } else if (OtherCondition) { Body } else { Body } if is the required keyword to start an if statement. (Condition) an expression which will be tested in order to decide if the next block will run or not. Body (in all places) is a list of statements(#statements) which will run if the prior condition resulted in a non-zero result. else if the required keyword to add another condition and body to the entire if statement. else the required keyword to add a final body to the if statement, which will only run when no other conditions are met. else if can be repeated any number of times, for any number of conditions. There can only be one else for each if statement.","title":"If"},{"location":"full-syntax/#for","text":"For loops follow the format: for (Init, Condition, Step) { Body } Init , Condition , and Step are all expressions which run at different points. Body is a list of statements(#statements) which will run each iteration of the loop. Init can optionally be a declaration and is run before the loop first stats, and never again. Condition is checked before the loop runs an iteration, and if it is false, the loop will stop. Step is run after each iteration of the loop.","title":"For"},{"location":"full-syntax/#break-continue","text":"Break and continue both follow the format: Break Continue With no extra code. The break and continue statements are only valid inside of for loops .","title":"Break-Continue"},{"location":"full-syntax/#return","text":"Return statements follow the format: Return Value Value is any kind of expression , which will be returned to the caller. Value must evaluate to a type compatible to the return type of the current function .","title":"Return"},{"location":"full-syntax/#expression-statements","text":"Expression statements follow the format: Expression Expression is any kind of expression . If Expression does not call a function or set a variable, it will be eliminated by the compiler during dead-code elimination.","title":"Expression-Statements"},{"location":"full-syntax/#expression","text":"Expressions follow many formats, examples: A := B + C (2 - E) / 2.5 9999 + *(G) % H Any unquoted text inside an expression is treated as a variable. Quoted text is treated as an i8* typed value. Numbers are treated as the smallest possible type to hold them (ex: 58 would be an i8 , 9999 would be an i16 ) Operands of any given operator must be a someone-similar type (ex: 2.6 * SomePointer is invalid). Operators are evaluated according to precedence and associativity, which is defined in Constants.ahk . Some operators may not be implemented for a given type Some expressions may be used as booleans inside of for loops or if statements . This is done by checking if the expressions results in 0 or not. Additionally, there is the format: Something[SomethingElse] Where Something is an expression which results in a pointer-type, and SomethingElse results in an integer, which will be used as an index into Something .","title":"Expression"},{"location":"full-syntax/#operator-list","text":"","title":"Operator list"},{"location":"full-syntax/#binary-operators","text":"Category Name Precedence Associativity Operators in category Assignment 0 Right := , += , -= , *= Logic 1 Right && , || Equality 2 Left != , = Comparison 3 Right < , <= , > , >= Unused 4 Addition 5 Left + , - Division 6 Left / , * , % Bitwise 7 Left & , | , ^ Module 8 N/A :","title":"Binary Operators"},{"location":"full-syntax/#unary-operators","text":"Operator Prefix/Postfix ++ Both -- Both ! Prefix ~ Prefix * Prefix & Prefix","title":"Unary Operators"},{"location":"full-syntax/#types","text":"A type is simply a combination of a identifier, with any number of * s after it (each * increases the level of nested pointers) The base type names are i8 , i16 , i32 , i64 f32 , f64 void With pointer (and pointer-pointer) types for each, like: void* - Pointer to void i16** - Pointer to a pointer to an i16 i8* - Pointer to an i8 void***************** - Pointer to a pointer to a pointer to a pointer to a pointer to a pointer to a pointer.... you get it","title":"Types"},{"location":"full-syntax/#names","text":"Names are simply combinations of characters and numbers. Names must start with a-z, but can contain numbers after the first letter.","title":"Names"},{"location":"how-it-works/","text":"The structure The compiler is laid out in various separate stages, in the order: Lexer Parser Optimizer Compiler CodeGen PEBuilder / ToAHK A quick rundown The lexer takes source code, makes it into an array of tokens. The parser takes an array of tokens, builds it into a tree that represents the code. The optimizer takes that tree, and removes useless bits. The compiler takes that optimized tree, and converts it into CPU instructions. CodeGen takes the CPU instructions that the compiler is trying to generate, but assembles them into raw machine code. PEBuilder packs the raw machine code into a .exe file. ToAHK packs the raw machine code into a .ahk file with helper functions to call the code. Simple enough, right? ((((it only took me 6000+ lines to do)))) Lexer The lexer is used to transform plain text like define i32 Main or i32 test := 99 + 2 into an array of \"tokens\". A token is like a word, and is the smallest unit that the entire compiler uses. Tokens also have different types. So, i32 test := 99 + 2 would have the tokenizer start with the character i , which it would see is: Not the start of an operator Not the start of a string, or character literal Not whitespace Not a new line Not a digit Is alphanumeric And now that the lexer has found an alphanumeric character, it will continue to consume all alphanumeric characters after the first. So, 32 would also be consumed, and added to the t token, however, is not alphanumeric, and would be the end of the t token. Next, to figure out the type of the token, the lexer checks if it is in the list of keywords (found in Constants.ahk ), and since it is not a keyword, the token is created with the type Tokens.IDENTIFIER , and a value of i32 . This would repeat for test , giving us the two tokens: [{Value: \"i32\", Type: Tokens.IDENTIFIER}, {Value: \"test\", Type: Tokens.IDENTIFIER}] Now, the lexer would see the character : , and : is defined as the first character of an operator (in Constants.ahk 's CharacterTokens.Operators ). Since : is an operator (or part of an operator), the lexer will now: Check if the next character is part of any operators (In this case the next character is = , which is part of := ) Gather all characters that are part of the operator which matches the next character ( := only has two characters, so this step is already done) Create a token of the Tokens.OPERATOR type, with the value of the found operator ( Tokens.COLON_EQUAL in this case) Now we've got: [{Value: \"i32\", Type: Tokens.IDENTIFIER}, {Value: \"test\", Type: Tokens.IDENTIFIER}, {Value: \":=\", Type: Tokens.OPERATOR}] And the next character is 9 , which the lexer would see is: Not the start of an operator Not the start of a string, or character literal Not whitespace Not a new line Is a digit Now, the lexer will gather all digits following the first, getting us 99 , and create a Tokens.INTEGER token, with the value 99 . (If the lexer found the character . inside the number, the token type would be Tokens.DOUBLE ) Now, applying these same rules to the rest of the string, we get the following array of tokens for the output: [ {Value: \"i32\", Type: Tokens.IDENTIFIER}, {Value: \"test\", Type: Tokens.IDENTIFIER}, {Value: \":=\", Type: Tokens.OPERATOR}, {Value: 99, Type: Tokens.INTEGER}, {Value: \"+\", Type: Tokens.OPERATOR}, {Value: 2, Type: Tokens.INTEGER} ] One thing that I haven't mentioned is that all token actually contain a bit more data. Each Token object contains a Context object, which stores: The source code that the token was extracted from Where in the source code the token was extracted from Context objects are used to display errors by taking Context.End - Context.Start , and appending that many ^ characters to the - line, which is drawn by appending Context.Start - LineStart - characters. And that's all the lexer really does. Of course, there's many-many more token types than I mentioned, and the lexer also has cases for hex/binary/octal literals, which are given the type Tokens.INTEGER . Parser The parser takes the array of tokens which the lexer outputs, and builds an abstract syntax tree out of the tokens. And abstract syntax tree (AST) is a how a given program is represented, in this case, each \"leaf\" of the AST is either a Token object (which the lexer outputs) or a ASTNode object. For example, the AST of 1 + 2 would be: { Type: ASTNodeTypes.BINARY, Left: { Type: Tokens.INTEGER, Value: 1 } Operator: { Type: Tokens.OPERATOR, Value: \"+\" } Right: { Type: Tokens.INTEGER, Value: 2 } } This concept is the same throughout the entire parser, you have an AST node, which has other AST nodes inside of it, which can represent any part of a program. Additionally, most AST nodes (that are single lines, like all expressions) also have Context properties, which are built using the Context of each token the node is mad up of. The hard part is actually building the AST. To build the AST, the parser starts with Parser.ParseProgram , which uses the array of tokens from the lexer (passed in Parser.__New ), and calls Parser.ParseProgramStatement until the parser has processed all of the given tokens. .ParseProgramStatement looks at the next token to be parsed, and does a few different things based on what the next token is: When the next token is a Tokens.KEYWORD and has the value Keywords.DEFINE , then the parser will call Parser.ParseDefine When the next token is a Tokens.KEYWORD and has the value Keywords.DLLIMPORT , then the parser will call Parser.ParseDllImport When the next token is a Tokens.KEYWORD and has the value Keywords.IMPORT , then the parser will add the following token to a running list of imported modules. When the next token is a Tokens.IDENTIFIER and is a valid type name, then the parser will call Parser.ParseDeclaration If none of the earlier cases were met, the parser will throw an error. In cases 1, 2, and 4, the parser branches off to a different function, which will try to match the stream of tokens to a format. Each of these formats can be found in the full syntax description , but as a quick example, here's the DllImport format: DllImport i32 FunctionName(i32, i32) {DllFileName.dll, FunctionNameInDLL} Which is the token type pattern of: DllImport i32 FunctionName ( i32 , i32 ) { DllFileName . dll , FunctionNameInDLL } Tokens.KEYWORD, Tokens.IDENTIFIER, Tokens.IDENTIFIER, Tokens.LEFT_PAREN, Tokens.IDENTIFIER, Tokens.COMMA, Tokens.IDENTIFIER, Tokens.RIGHT_PAREN, Tokens.LEFT_BRACKET, Tokens.IDENTIFIER, Tokens.DOT, Tokens.IDENTIFIER, Tokens.COMMA, Tokens.IDENTIFIER, Tokens.RIGHT_BRACKET And when a DllImport statement does not match this pattern, then there is a syntax error. The entire parser follows this general idea, you have a token type pattern associated with an AST node type, and when the token stream matches that pattern, then it can be consumed and built into an AST node. When the token stream only partially matches the pattern, then there is a syntax error. For example, DllImport i32 123() {Fn.doo, \"hello world\"} Does not match the Tokens.IDENTIFIER rule for FunctionName , since 123 is a Tokens.INTEGER . Then \"hello world\" does not match the Tokens.IDENTIFER rule for DllFileName . Both of these are syntax errors, and will be detected by the parser. Now, for something a bit more advanced, we'll mode on to the Define statement, which follows the Define ReturnType FunctionName(ParameterList) { Body } pattern (and is handled by .ParseDefine ). Since everything but Body was already defined in the last example, we'll jump straight to that. After everything up to { has been parsed, the parser calls into .ParseBlock , which consumes the { token, and calls .ParseStatement until it reaches a } token. Now, looking into .ParseStatement , you can see it has three branches: When the next token is a keyword, call into .ParseKeywordStatement When the next token is an identifier, and a valid type name, call into .ParseDeclaration Else, call into .ParseExpressionStatement I'm only going to talk about the first and third options, since .ParseDeclaration doesn't do much, and is pretty much the same kind of matching as DllImport . So, .ParseKeywordStatement is for when we've already matched a Tokens.KEYWORD type token, so by switching on the Value of that token, we can figure out which kind of statement is starting. The statement types and actions are: For a Keywords.RETURN, return a return AST node, which returns the value given by .ParseExpressionStatement (which I'll get to later) For a Keywords.IF, return the result of .ParseIf For a Keywords.ELSE, throw an error, since any else if / else statements are parsed by .ParseIf For a Keywords.FOR, return the result of .ParseFor For a Keywords.CONTINUE or Keywords.BREAk, return a ContinueBreak node, with the keyword used (\"continue\" or \"break\") If none of these have matched, then throw an error. I'm just going to go through the Keywords.IF case, since it uses all of the capabilities that the other cases use, and will explain everything you need to know. So, now we're inside of .ParseIf , and this first think we do is build an if AST node using .ParseExpression and .ParseBlock . You might notice that we already called .ParseBlock back in .ParseDefine , and that is a key part of the parser. This parser is a \"recursive descent parser\" (which sounds super cool), which means that through recursive function calls, the call stack itself takes the shape of the AST as we parse the program. For example: define i32 abc() { if (1) { return 8 } } Would have the call stack (bottom = first call, top = most recent call) .ParseExpression (Handles the 8 after return) .ParseKeywordStatement (Handles return) .ParseBlock (Handles {} after the if) .ParseIf (Handles the if) .ParseBlock (Handles {} after abc) .ParseDefine (Handles the define) .ParseProgram and the AST is { Type: \"Program\", Functions: [ { Type: \"Define\", Body: [ { Type: \"If\", Body: [ { Type: \"Return\", Value: 8 } ] } ] } ] } Which means that by using the result of a .ParseXXXXX method inside of another .ParseXXXXX method to build a new AST node, we can summon a properly structured AST out of thin air. Which is pretty neat. Now, back to .ParseIf . The template is if Expression { Body } else if Expression { Body } else Expression { Body } Where: if Expression only occurs once, at the start of this \"chain\" of statements else if Expression can be repeated as many times as you'd like else can only occur once, at the end of the chain Each Expression is parsed by .ParseExpression , which we'll get into next, and each Body is parsed with .ParseBlock . And since the results of these .ParseXXXX calls are being used to build a bigger AST node, we are taking advantage of the recursive descent parser again to build AST nodes. Now, this is how all statements are parsed, first they match a token type pattern, and then they contain other AST nodes that make up the statements themselves. The only exception to this style is expressions, since they do not fit a set token type pattern, and are much more unpredictable. Expressions The parser does not use recursive descent to parse expressions, so it's worth separating the two part. Instead, the parser uses the \"shunting yard algorithm\", which sounds much less cool than recursive descent, but is an incredible technique. I actually don't understand the shunting yard algorithm enough to explain it fully, but the general idea is: At the start of parsing an expression, set up an \"Operator\" stack, and an \"Operand\" stack. Iterate through each token of the expression, and: When you find data (Like a number, string, or variable), push it onto the \"Operand\" stack and continue the loop. (This is not part of the standard algorithm) When you find '(', call .ParseGrouping to parse the grouping, and push it onto the \"Operand\" stack. When you find an operator, go through the \"Operator\" stack, and check the \"Precedence\" of the current operator against the one on the top of the stack. If the operator on the top of the stack has higher precedence than the current operator (meaning that you should check if it should be evaluated before the current operator) Then pop two operands off the \"Operand\" stack, and build an AST node with (PoppedOperand1, PoppedOperator, PoppedOperand2), and push it onto the \"Operand\" stack Continue this for the entire \"Operator\" stack, until you find an operator with lower precedence than the current operator, or the \"Operator\" stack is empty Finally, push the current operator onto the \"Operator\" stack Once all tokens are consumed, loop through any operators left in the \"Operator\" stack, and pop two operands from the \"Operand\" stack for each, then push them back onto the \"Operand\" stack. Return OperandStack[1] So, for example, 1 * 2 + 3 would be parsed with the following steps: Start with 1 , it's data, so we'll push it onto the operand stack OperandStack = [1] OperatorStack = [] Next we have * , which is an operator, and since the operator stack is empty, all we do is push it onto the operator stack OperandStack = [1] OperatorStack = [\"*\"] Next up is 2 , which is data again OperandStack = [1, 2] OperatorStack = [\"*\"] And now we've got + , which is an operator, and since the operator stack has something in it, we need to check + 's precedence against * 's precedence. Now, + has a precedence of 5, and * has a precedence of 6 , which means that * needs to be evaluated before + . So, we'll pop two operands off of the operand stack, and combine 1, *, 2 into a single Binary AST node, and push that onto the operand stack. Finally, we push + onto the operator stack. OperandStack = [{Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2}] OperatorStack = [\"+\"] Next is 3 , which is data, so it goes onto the operand stack, leaving us with: OperandStack = [{Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2}, 3] OperatorStack = [\"+\"] And before we return a result, we go through the operator stack one last time, and build AST nodes for each operator left on the stack. So, we pop + off the operator stack, pop 3 and {Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2} off of the operand stack, and build the AST node: {Type: ASTNodeTypes.BINARY, Left: {Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2}, Operator: \"+\", Right: 3} And push it onto the operand stack. Then finally, we return OperandStack[1] , which is that same AST node we just built, giving us { Type: ASTNodeTypes.BINARY, Left: { Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2 }, Operator: \"+\", Right: 3 } Aka (1 * 2) + 3 And that's the parser, a little oversimplified, but I think it gets the general design across well enough. If you're interested in either of the parsing techniques used, google them, there's load of good articles and graphics explaining them better than I can. Optimizer The optimizer takes the resulting AST from the parser, and walks it, replacing AST nodes with slightly optimized versions of themselves. The \"walking\" is done by recursively visiting each branch of an AST node, so a binary expression would have the \"Left\" and \"Right\" branches optimized before the binary expression itself is optimized. Most of the optimizer depends on .IsConstant , and .ExpressionHasSideEffects , which are both used to determine if an expression is a candidate for being optimized or removed entirely. And AST node which contains an ASTNodeTypes.EXPRESSION is optimized by calling .Optimize%ExpressionType% , which: For unary expressions, nothing. I do not optimize unary expressions, mostly because only ~2 of the unary operators don't have side-effects. For binary expressions, I optimize both sides, and if both sides are constant values (ex: 1 and 2), then I manually evaluate the expression, and build a token containing the new result. For grouping, I optimize all sub-expressions, and then remove any which do not have side-effects. (for example, (1, 2 + 3) would become 1 , since 2 + 3 has no side-effects, and only wastes space) Function calls are not optimized, since I got lazy while writing the optimizer. Additionally, some statements are optimized: For if statements, if an else if has a constant condition which is false, the entire else if is eliminated, and when an else if has a constant true condition, all else if s after are eliminated. Expression statements are totally eliminated if they do not have side-effects, for example, 1 + 2 alone on a line would be eliminated. And that's the optimizer. It's very basic, and I wish I'd written more for it, but I was reaching max-burnout while writing it. Compiler The compiler takes the optimized AST from the optimizer, and walks it, calling into CodeGen to generate machine code for each AST node it visits. The AST walking is done in the same way as the optimizer, with each AST node calling .Compile for any leaves it has. Statements are compiled in mostly-similar ways, with a condition being compiled, then tested, and a conditional jump to either the next statement in a chain, or out of the current statement, or more specifically: If statements are compiled by compiling the condition expression, testing it with result != 0 , and conditionally jumping into the Body for the statement. After the body, a jmp to the end of the statement stops any other branches from running. If the != 0 test fails, it jmp s to the next condition and body to be checked. For loops are compiled with the initialization step first, then a label to jump back to, then the condition (and a jump out of the loop when the condition is false), and then the loop body. After the body is the step expression, and a jump back to the start of the loop. Break/Continue are compiled by jumping either out of the current loop, or the end of the current loop, using the .CurrentForLoop property which holds a label name for the current for loop. Return statements are compiled by jumping to a special label for the current function ( __Return then the number of functions compiled before this one) which is placed at the end of the function Function definitions are compiled with a label in the format __Define__FunctionName which can be used to call the function via a relative offset. Then the entire function body is compiled, and postlude code is generated to clean up the stack, and then return from the function. Expressions are a little less label/ jmp intensive, but more complex to understand. So, to evaluate expressions, a stack is used to hold operands until they are needed, which means that: When we compile a binary operator, we should pop two operands of the stack, and push our result onto the stack. When we compile a unary operator, we should pop one operand, and push our result onto the the stack. When we compile a function call, we should pop as many operands as the function takes as parameters, and then push the return value onto the stack. As long as all generated code to evaluate expressions follows these rules, you can always trust an expression to leave its result on the stack. If this promise of operands/results is every broken, then there has been a code mis-generation, and something is wrong. However, since it isn't broken, expressions can be compiled into a series of very basic instructions. So, let's walk through code generation for 1 + (2 * A) . The very first step is to push 1 onto the stack, since the first + requires two operands, both of which will need to be on the stack according to our evaluation rules from above. The AST walking for this is actually .Compile(Expression.Left) .Compile(Expression.Right) Where a token is compiled down to a simple push 1 Now that Expression.Left is compiled, we need to compiled Expression.Right , which happens to be another ASTNodeTypes.BINARY , so we'll do the same thing again: .Compile(Expression.Left) Will generate push 2 And then .Compile(Expression.Left) Will generate push [r15 + (0 * 8)] ( 0 * 8 since A is the 0th variable, and R15 always holds a pointer to the local variables in a given function) Now to compile * , we'll pop two operands off the stack, into RBX and then RAX pop RBX pop RAX So, RAX = ResultOf(Expression.Left) and RBX = ResultOf(Expression.Right) , which means we're ready to generate code to do the first operation ( * ) imul RAX, RBX And in order to follow the rule of pushing our result back onto the stack for another expression, we finish with push RAX Which gives us this (see below) code to evaluate the expression (2 * A) push 1 push 2 push [r15 + (0 * 8)] pop RBX pop RAX add RAX, RBX push RAX Once the CPU finishes the push RAX instruction, the stack will be laid out as so: [1, ResultOf(\"2 * A\")] Which you might notice are the two operands for 1 + (2 * A) , so now all we need to do to compile the + operator is pop RBX pop RAX To load the two operands, and then add RAX, RBX to do the operation, and finally push RAX to store the result. Now we're left with the final generated code of: push 1 ; The result of the token '1' push 2 ; The result of the token '2' push [r15 + (0 * 8)] ; The result of the token 'A' pop RBX ; Right operand, the result of the last expression evaluated ('A' in this case) pop RAX ; Left operand, the result of the 2nd to last expression evaluated ('2' in this case) imul RAX, RBX push RAX ; Stores the result of (Left * Right) as the result of the last expression evaluated pop RBX ; Right operand, result of the last expression evaluated ('2 * A' in this case) pop RAX ; Left operand, result of the 2nd to last expression evaluated ('1' in this case) add RAX, RBX push RAX ; Stores the result of `(Left + Right)` as the result of the last expression evaluated And a quick example with a unary operator instead, 1 + !2 : .Compile(Expression.Left) Generates: push 1 .Compile(Expression.Right) Generates code to evaluate !2 , which in itself runs .Compile(UnaryExpression.Operand) , generating the code: push 2 And then evaluating the operand with pop RAX not RAX push RAX And now we've got both the operands on the stack, so we generate code for + : pop RBX pop RAX add RAX, RBX push RAX Which leaves us with push 1 push 2 pop RAX not RAX push RAX pop RBX pop RAX add RAX, RBX push RAX So, thanks to these expression evaluation rules, all that's needed to add an new operator is to add it to CodeGen , and implement it enough that it will use RAX and RBX as operands, and push a result onto the stack. Now, you might notice that this generates some pretty bad code, with lots of stack usage, which is bad for speed and code size. To get around this, I lied I little bit during these examples. The generated code doesn't actually use the CPU stack, instead it uses the registers [RCX, RDX, R8, R9, R10, R11, R12, R13] as a fake stack, which the compiler will automatically keep track of what parts are being used. This eliminates lots of the extra push and pop -ing, since our 1 + (2 * A) example would be generated as mov RCX, 1 ; Push register stack, store value into new top of stack mov RDX, 2 ; Same as above mov R8, [r15 + (0 * 8)] ; Same as above imul RDX, R8 ; Pop register stack twice, multiply popped registers, store result into the top of stack add RCX, RDX ; Same as above, just with multiplication. Of course, this optimization isn't perfect, and extra instructions are still generated, but this reduces the bloat a lot, and by keeping operands in registers, it also improves speed. Type Checking Type checking is done as a bit of an afterthought, but the general idea is that each .CompileXXXX method will return the type of the value which it has pushed onto the stack. And by using the returned type, we can check if it is compatible with the types of other components of a given AST node. For example, to compile a binary expression, we have the code: LeftType := this.Compile(Expression.Left) RightType := this.Compile(Expression.Right) And then later on, we have: ResultType := this.Typing.ResultType(LeftType, RightType) And when there is no result type for that combination of operand types, and exception is thrown. For example \"Abc\" * 2.5 Would have LeftType = i8* , and RightType = f64 . Which are two obviously incompatible types. However, if we have two operands that are similar types, but not the exact same type, there can be an implicit cast, for example: 1 * 2.5 Would have LeftType = i8 , and RightType = f64 . However, since both types are numeric, and floating pointer numbers are considered more precise, the compiler would get ResultType = f64 . And to ensure that both operands are actually compatible, and not just theoretically compatible, each .CompileXXXXXExpression will include calls to this.Cast(RightType, ResultType) and this.Cast(LeftType, ResultType) . .Cast takes the current type of the value on top of the stack, and the desired type, and converts them via the .Cast_FirstTypeName_SecondTypeName methods. So, in this case, first 2.5 would be cast to f64 (which requires no extra code to be generated, since it is already that type), and then 1 would be cast to f64 . For casting to/from floating point numbers, the instructions FILD / FSTP and FLD / FISTP instructions are used, which For FILD / FSTP : loads an integer into an FPU register as a floating point number, and then writes that integer back as a floating point number For FLD / FISTP : loads a floating point number into an FPU register, and then writes that float back as an integer The only other casts are integer size conversions, which are done by the CBWE , CWDE , CDQE instructions, aka: Convert byte to word (i8 -> i16) Convert word to double word (i16 -> i32) Convert double word to quad word (i32 -> i64) Type checking is also done for function calls and return values through checking if each parameter is of the correct type while compiling each parameter, and for return types, it is done when compiling return statements. Strings And Other Stuff The compiler handles strings by allocating StrLen(String) + 1 bytes much of stack space for each string, and encodes string literals into 64 bit integers, which when pushed onto the stack, will build the correctly ordered string. Actual references to strings are replaced by references to the hidden local variables __String__Full Text Of The String , which is then set to a pointer into the stack where the string was pushed. So, \"Hello world\" is compiled into a series of instructions like mov rax, 0 push rax mov rax, 217478657420656D push rax mov rax, 6F73207265746E45 push rax (Note, that's not actually \"Hello World\", I just copied that out of a random example .exe ) Parameters are treated exactly the same as locals, and all variables can be addressed using a \"SIB\" (See CodeGen for what that means), which allows getting/setting variables with minimum boilerplate. Function calls are a bit of a mess. Since the register stack uses some of the parameter registers, first the register stack has to be saved, and then the parameter registers have to be 0'd, and finally, the parameters can be compiled and moved into the parameter registers. When a function never has a return statement compiled, the return value is automatically set to 0. This is the only difference for omitting return , since the code to return from a function is automatically generated at the end of a function either way. Signed numbers are the only kind of numbers, unsigned operations require entirely different instructions for operations, which is why I don't plan on adding unsigned types. CodeGen This one will be shorter, I promise. CodeGen is a class which generates the correct bytes for lots of common AMD64 instructions, and automatically handles linking labels and jumps for you. This is done by storing an internal array of bytes, which contains assembled instructions, with objects pushed onto the array when CodeGen does not have enough information at the time to link the given label to an address. Additionally, CodeGen pushes objects for pointers to global variables, and pointers to functions imported from Dll files. CodeGen doesn't actually process these extra objects, but keeps them intact until either the \"second stage\" linkers in PEBuilder or ToAHK can link the code to actual pointers. The backbone of CodeGen is just a few methods: .REX(REXBits) Which will build a \"REX prefix\" for an instruction, which will promote the instruction to use 64 bit registers and data, along with giving it access to the new GPRs R8-R15. .REXOpcode(OpcodeBytes, REXParts) Which will build a REX prefix, and then write an opcode. .REXOpcodeMod(OpcodeBytes, DestRegister, SourceRegister, Options) Which will build a REX prefix, write the opcode, and then write a \"ModRM\" byte, which controls the operands, and operand types of an instruction. .REXOpcodeModSIB(Opcode, Register, SIB, Options) Which will build a REX prefix, opcode, and ModRM byte which uses the SIB addressing mode. SIB stands for (S)cale (I)ndex (B)ase, which allows you to have address calculations like FinalAddress = GetRegisterValue(SIB.Base) + (GetRegisterValue(SIB.Index) * SIB.Scale) , which are very useful for indexing the local table, global table, and import table. .NumberSizeOf(Number) Which returns the minimum number of bits needed to store the given number (used for instruction selection). .SplitIntoBytes32(Number) Which splits a 32 bit number into bytes, and stores it big-endian (like the processor expects). .SplitIntoBytes64(Number) Same as above, but with a 64 bit number. .Link() Which will resolve all labels, and return the partially linked code for a second stage linker. PEBuilder A class that handles all the dirty work of building .exe files. Most of the code is spent building the headers, and setting the correct magic numbers. The only interesting bit is how the import address table (IAT) and .reloc (relocation) section is built. The IAT is built with one structure for each Dll that functions are imported from, and 2 parallel arrays which hold the actual import data. The structure holds a pointer to the first array, the number of entries in all of the arrays, a pointer to the Dll name, and a pointer to the 2rd array. Each entry in the 1st and 2nd array is identical until the .exe file is loaded, but before that, an entry considered part of a \"hint-name table\", which is made up of an ordinal value for the imported function, or a pointer to the function's name. I do not bother with ordinal values. Once the loader reads the hint-name table, each entry in the 2nd array is overwritten with a pointer to the function it originally imported, which PEBuilder links code to jump into. The .reloc section handles what should happen when the file can't be loaded at the specified base address, and contains pointers to every location inside of the code which references a static address. So, every use of a global variable, and every use of an import function, gets an entry in the .reloc section. If you're wondering, the default section layout (which you can't change) is: Section Name What it's for .data Holds global variables .text Holds compiled code, and the program entry point .idata Holds the IAT, hint-name table, import file/name strings .reloc Holds the relocation info ToAHK A single function, which just dumps a program as a bunch of AHK functions It pretends to be the windows loader via some boilerplate, and pretends to be PEBuilder in the same boilerplate, by linking global pointers and imported function pointers. There's really not much to say about it.","title":"How it works"},{"location":"how-it-works/#the-structure","text":"The compiler is laid out in various separate stages, in the order: Lexer Parser Optimizer Compiler CodeGen PEBuilder / ToAHK","title":"The structure"},{"location":"how-it-works/#a-quick-rundown","text":"The lexer takes source code, makes it into an array of tokens. The parser takes an array of tokens, builds it into a tree that represents the code. The optimizer takes that tree, and removes useless bits. The compiler takes that optimized tree, and converts it into CPU instructions. CodeGen takes the CPU instructions that the compiler is trying to generate, but assembles them into raw machine code. PEBuilder packs the raw machine code into a .exe file. ToAHK packs the raw machine code into a .ahk file with helper functions to call the code. Simple enough, right? ((((it only took me 6000+ lines to do))))","title":"A quick rundown"},{"location":"how-it-works/#lexer","text":"The lexer is used to transform plain text like define i32 Main or i32 test := 99 + 2 into an array of \"tokens\". A token is like a word, and is the smallest unit that the entire compiler uses. Tokens also have different types. So, i32 test := 99 + 2 would have the tokenizer start with the character i , which it would see is: Not the start of an operator Not the start of a string, or character literal Not whitespace Not a new line Not a digit Is alphanumeric And now that the lexer has found an alphanumeric character, it will continue to consume all alphanumeric characters after the first. So, 32 would also be consumed, and added to the t token, however, is not alphanumeric, and would be the end of the t token. Next, to figure out the type of the token, the lexer checks if it is in the list of keywords (found in Constants.ahk ), and since it is not a keyword, the token is created with the type Tokens.IDENTIFIER , and a value of i32 . This would repeat for test , giving us the two tokens: [{Value: \"i32\", Type: Tokens.IDENTIFIER}, {Value: \"test\", Type: Tokens.IDENTIFIER}] Now, the lexer would see the character : , and : is defined as the first character of an operator (in Constants.ahk 's CharacterTokens.Operators ). Since : is an operator (or part of an operator), the lexer will now: Check if the next character is part of any operators (In this case the next character is = , which is part of := ) Gather all characters that are part of the operator which matches the next character ( := only has two characters, so this step is already done) Create a token of the Tokens.OPERATOR type, with the value of the found operator ( Tokens.COLON_EQUAL in this case) Now we've got: [{Value: \"i32\", Type: Tokens.IDENTIFIER}, {Value: \"test\", Type: Tokens.IDENTIFIER}, {Value: \":=\", Type: Tokens.OPERATOR}] And the next character is 9 , which the lexer would see is: Not the start of an operator Not the start of a string, or character literal Not whitespace Not a new line Is a digit Now, the lexer will gather all digits following the first, getting us 99 , and create a Tokens.INTEGER token, with the value 99 . (If the lexer found the character . inside the number, the token type would be Tokens.DOUBLE ) Now, applying these same rules to the rest of the string, we get the following array of tokens for the output: [ {Value: \"i32\", Type: Tokens.IDENTIFIER}, {Value: \"test\", Type: Tokens.IDENTIFIER}, {Value: \":=\", Type: Tokens.OPERATOR}, {Value: 99, Type: Tokens.INTEGER}, {Value: \"+\", Type: Tokens.OPERATOR}, {Value: 2, Type: Tokens.INTEGER} ] One thing that I haven't mentioned is that all token actually contain a bit more data. Each Token object contains a Context object, which stores: The source code that the token was extracted from Where in the source code the token was extracted from Context objects are used to display errors by taking Context.End - Context.Start , and appending that many ^ characters to the - line, which is drawn by appending Context.Start - LineStart - characters. And that's all the lexer really does. Of course, there's many-many more token types than I mentioned, and the lexer also has cases for hex/binary/octal literals, which are given the type Tokens.INTEGER .","title":"Lexer"},{"location":"how-it-works/#parser","text":"The parser takes the array of tokens which the lexer outputs, and builds an abstract syntax tree out of the tokens. And abstract syntax tree (AST) is a how a given program is represented, in this case, each \"leaf\" of the AST is either a Token object (which the lexer outputs) or a ASTNode object. For example, the AST of 1 + 2 would be: { Type: ASTNodeTypes.BINARY, Left: { Type: Tokens.INTEGER, Value: 1 } Operator: { Type: Tokens.OPERATOR, Value: \"+\" } Right: { Type: Tokens.INTEGER, Value: 2 } } This concept is the same throughout the entire parser, you have an AST node, which has other AST nodes inside of it, which can represent any part of a program. Additionally, most AST nodes (that are single lines, like all expressions) also have Context properties, which are built using the Context of each token the node is mad up of. The hard part is actually building the AST. To build the AST, the parser starts with Parser.ParseProgram , which uses the array of tokens from the lexer (passed in Parser.__New ), and calls Parser.ParseProgramStatement until the parser has processed all of the given tokens. .ParseProgramStatement looks at the next token to be parsed, and does a few different things based on what the next token is: When the next token is a Tokens.KEYWORD and has the value Keywords.DEFINE , then the parser will call Parser.ParseDefine When the next token is a Tokens.KEYWORD and has the value Keywords.DLLIMPORT , then the parser will call Parser.ParseDllImport When the next token is a Tokens.KEYWORD and has the value Keywords.IMPORT , then the parser will add the following token to a running list of imported modules. When the next token is a Tokens.IDENTIFIER and is a valid type name, then the parser will call Parser.ParseDeclaration If none of the earlier cases were met, the parser will throw an error. In cases 1, 2, and 4, the parser branches off to a different function, which will try to match the stream of tokens to a format. Each of these formats can be found in the full syntax description , but as a quick example, here's the DllImport format: DllImport i32 FunctionName(i32, i32) {DllFileName.dll, FunctionNameInDLL} Which is the token type pattern of: DllImport i32 FunctionName ( i32 , i32 ) { DllFileName . dll , FunctionNameInDLL } Tokens.KEYWORD, Tokens.IDENTIFIER, Tokens.IDENTIFIER, Tokens.LEFT_PAREN, Tokens.IDENTIFIER, Tokens.COMMA, Tokens.IDENTIFIER, Tokens.RIGHT_PAREN, Tokens.LEFT_BRACKET, Tokens.IDENTIFIER, Tokens.DOT, Tokens.IDENTIFIER, Tokens.COMMA, Tokens.IDENTIFIER, Tokens.RIGHT_BRACKET And when a DllImport statement does not match this pattern, then there is a syntax error. The entire parser follows this general idea, you have a token type pattern associated with an AST node type, and when the token stream matches that pattern, then it can be consumed and built into an AST node. When the token stream only partially matches the pattern, then there is a syntax error. For example, DllImport i32 123() {Fn.doo, \"hello world\"} Does not match the Tokens.IDENTIFIER rule for FunctionName , since 123 is a Tokens.INTEGER . Then \"hello world\" does not match the Tokens.IDENTIFER rule for DllFileName . Both of these are syntax errors, and will be detected by the parser. Now, for something a bit more advanced, we'll mode on to the Define statement, which follows the Define ReturnType FunctionName(ParameterList) { Body } pattern (and is handled by .ParseDefine ). Since everything but Body was already defined in the last example, we'll jump straight to that. After everything up to { has been parsed, the parser calls into .ParseBlock , which consumes the { token, and calls .ParseStatement until it reaches a } token. Now, looking into .ParseStatement , you can see it has three branches: When the next token is a keyword, call into .ParseKeywordStatement When the next token is an identifier, and a valid type name, call into .ParseDeclaration Else, call into .ParseExpressionStatement I'm only going to talk about the first and third options, since .ParseDeclaration doesn't do much, and is pretty much the same kind of matching as DllImport . So, .ParseKeywordStatement is for when we've already matched a Tokens.KEYWORD type token, so by switching on the Value of that token, we can figure out which kind of statement is starting. The statement types and actions are: For a Keywords.RETURN, return a return AST node, which returns the value given by .ParseExpressionStatement (which I'll get to later) For a Keywords.IF, return the result of .ParseIf For a Keywords.ELSE, throw an error, since any else if / else statements are parsed by .ParseIf For a Keywords.FOR, return the result of .ParseFor For a Keywords.CONTINUE or Keywords.BREAk, return a ContinueBreak node, with the keyword used (\"continue\" or \"break\") If none of these have matched, then throw an error. I'm just going to go through the Keywords.IF case, since it uses all of the capabilities that the other cases use, and will explain everything you need to know. So, now we're inside of .ParseIf , and this first think we do is build an if AST node using .ParseExpression and .ParseBlock . You might notice that we already called .ParseBlock back in .ParseDefine , and that is a key part of the parser. This parser is a \"recursive descent parser\" (which sounds super cool), which means that through recursive function calls, the call stack itself takes the shape of the AST as we parse the program. For example: define i32 abc() { if (1) { return 8 } } Would have the call stack (bottom = first call, top = most recent call) .ParseExpression (Handles the 8 after return) .ParseKeywordStatement (Handles return) .ParseBlock (Handles {} after the if) .ParseIf (Handles the if) .ParseBlock (Handles {} after abc) .ParseDefine (Handles the define) .ParseProgram and the AST is { Type: \"Program\", Functions: [ { Type: \"Define\", Body: [ { Type: \"If\", Body: [ { Type: \"Return\", Value: 8 } ] } ] } ] } Which means that by using the result of a .ParseXXXXX method inside of another .ParseXXXXX method to build a new AST node, we can summon a properly structured AST out of thin air. Which is pretty neat. Now, back to .ParseIf . The template is if Expression { Body } else if Expression { Body } else Expression { Body } Where: if Expression only occurs once, at the start of this \"chain\" of statements else if Expression can be repeated as many times as you'd like else can only occur once, at the end of the chain Each Expression is parsed by .ParseExpression , which we'll get into next, and each Body is parsed with .ParseBlock . And since the results of these .ParseXXXX calls are being used to build a bigger AST node, we are taking advantage of the recursive descent parser again to build AST nodes. Now, this is how all statements are parsed, first they match a token type pattern, and then they contain other AST nodes that make up the statements themselves. The only exception to this style is expressions, since they do not fit a set token type pattern, and are much more unpredictable.","title":"Parser"},{"location":"how-it-works/#expressions","text":"The parser does not use recursive descent to parse expressions, so it's worth separating the two part. Instead, the parser uses the \"shunting yard algorithm\", which sounds much less cool than recursive descent, but is an incredible technique. I actually don't understand the shunting yard algorithm enough to explain it fully, but the general idea is: At the start of parsing an expression, set up an \"Operator\" stack, and an \"Operand\" stack. Iterate through each token of the expression, and: When you find data (Like a number, string, or variable), push it onto the \"Operand\" stack and continue the loop. (This is not part of the standard algorithm) When you find '(', call .ParseGrouping to parse the grouping, and push it onto the \"Operand\" stack. When you find an operator, go through the \"Operator\" stack, and check the \"Precedence\" of the current operator against the one on the top of the stack. If the operator on the top of the stack has higher precedence than the current operator (meaning that you should check if it should be evaluated before the current operator) Then pop two operands off the \"Operand\" stack, and build an AST node with (PoppedOperand1, PoppedOperator, PoppedOperand2), and push it onto the \"Operand\" stack Continue this for the entire \"Operator\" stack, until you find an operator with lower precedence than the current operator, or the \"Operator\" stack is empty Finally, push the current operator onto the \"Operator\" stack Once all tokens are consumed, loop through any operators left in the \"Operator\" stack, and pop two operands from the \"Operand\" stack for each, then push them back onto the \"Operand\" stack. Return OperandStack[1] So, for example, 1 * 2 + 3 would be parsed with the following steps: Start with 1 , it's data, so we'll push it onto the operand stack OperandStack = [1] OperatorStack = [] Next we have * , which is an operator, and since the operator stack is empty, all we do is push it onto the operator stack OperandStack = [1] OperatorStack = [\"*\"] Next up is 2 , which is data again OperandStack = [1, 2] OperatorStack = [\"*\"] And now we've got + , which is an operator, and since the operator stack has something in it, we need to check + 's precedence against * 's precedence. Now, + has a precedence of 5, and * has a precedence of 6 , which means that * needs to be evaluated before + . So, we'll pop two operands off of the operand stack, and combine 1, *, 2 into a single Binary AST node, and push that onto the operand stack. Finally, we push + onto the operator stack. OperandStack = [{Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2}] OperatorStack = [\"+\"] Next is 3 , which is data, so it goes onto the operand stack, leaving us with: OperandStack = [{Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2}, 3] OperatorStack = [\"+\"] And before we return a result, we go through the operator stack one last time, and build AST nodes for each operator left on the stack. So, we pop + off the operator stack, pop 3 and {Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2} off of the operand stack, and build the AST node: {Type: ASTNodeTypes.BINARY, Left: {Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2}, Operator: \"+\", Right: 3} And push it onto the operand stack. Then finally, we return OperandStack[1] , which is that same AST node we just built, giving us { Type: ASTNodeTypes.BINARY, Left: { Type: ASTNodeTypes.BINARY, Left: 1, Operator: \"*\", Right: 2 }, Operator: \"+\", Right: 3 } Aka (1 * 2) + 3 And that's the parser, a little oversimplified, but I think it gets the general design across well enough. If you're interested in either of the parsing techniques used, google them, there's load of good articles and graphics explaining them better than I can.","title":"Expressions"},{"location":"how-it-works/#optimizer","text":"The optimizer takes the resulting AST from the parser, and walks it, replacing AST nodes with slightly optimized versions of themselves. The \"walking\" is done by recursively visiting each branch of an AST node, so a binary expression would have the \"Left\" and \"Right\" branches optimized before the binary expression itself is optimized. Most of the optimizer depends on .IsConstant , and .ExpressionHasSideEffects , which are both used to determine if an expression is a candidate for being optimized or removed entirely. And AST node which contains an ASTNodeTypes.EXPRESSION is optimized by calling .Optimize%ExpressionType% , which: For unary expressions, nothing. I do not optimize unary expressions, mostly because only ~2 of the unary operators don't have side-effects. For binary expressions, I optimize both sides, and if both sides are constant values (ex: 1 and 2), then I manually evaluate the expression, and build a token containing the new result. For grouping, I optimize all sub-expressions, and then remove any which do not have side-effects. (for example, (1, 2 + 3) would become 1 , since 2 + 3 has no side-effects, and only wastes space) Function calls are not optimized, since I got lazy while writing the optimizer. Additionally, some statements are optimized: For if statements, if an else if has a constant condition which is false, the entire else if is eliminated, and when an else if has a constant true condition, all else if s after are eliminated. Expression statements are totally eliminated if they do not have side-effects, for example, 1 + 2 alone on a line would be eliminated. And that's the optimizer. It's very basic, and I wish I'd written more for it, but I was reaching max-burnout while writing it.","title":"Optimizer"},{"location":"how-it-works/#compiler","text":"The compiler takes the optimized AST from the optimizer, and walks it, calling into CodeGen to generate machine code for each AST node it visits. The AST walking is done in the same way as the optimizer, with each AST node calling .Compile for any leaves it has. Statements are compiled in mostly-similar ways, with a condition being compiled, then tested, and a conditional jump to either the next statement in a chain, or out of the current statement, or more specifically: If statements are compiled by compiling the condition expression, testing it with result != 0 , and conditionally jumping into the Body for the statement. After the body, a jmp to the end of the statement stops any other branches from running. If the != 0 test fails, it jmp s to the next condition and body to be checked. For loops are compiled with the initialization step first, then a label to jump back to, then the condition (and a jump out of the loop when the condition is false), and then the loop body. After the body is the step expression, and a jump back to the start of the loop. Break/Continue are compiled by jumping either out of the current loop, or the end of the current loop, using the .CurrentForLoop property which holds a label name for the current for loop. Return statements are compiled by jumping to a special label for the current function ( __Return then the number of functions compiled before this one) which is placed at the end of the function Function definitions are compiled with a label in the format __Define__FunctionName which can be used to call the function via a relative offset. Then the entire function body is compiled, and postlude code is generated to clean up the stack, and then return from the function. Expressions are a little less label/ jmp intensive, but more complex to understand. So, to evaluate expressions, a stack is used to hold operands until they are needed, which means that: When we compile a binary operator, we should pop two operands of the stack, and push our result onto the stack. When we compile a unary operator, we should pop one operand, and push our result onto the the stack. When we compile a function call, we should pop as many operands as the function takes as parameters, and then push the return value onto the stack. As long as all generated code to evaluate expressions follows these rules, you can always trust an expression to leave its result on the stack. If this promise of operands/results is every broken, then there has been a code mis-generation, and something is wrong. However, since it isn't broken, expressions can be compiled into a series of very basic instructions. So, let's walk through code generation for 1 + (2 * A) . The very first step is to push 1 onto the stack, since the first + requires two operands, both of which will need to be on the stack according to our evaluation rules from above. The AST walking for this is actually .Compile(Expression.Left) .Compile(Expression.Right) Where a token is compiled down to a simple push 1 Now that Expression.Left is compiled, we need to compiled Expression.Right , which happens to be another ASTNodeTypes.BINARY , so we'll do the same thing again: .Compile(Expression.Left) Will generate push 2 And then .Compile(Expression.Left) Will generate push [r15 + (0 * 8)] ( 0 * 8 since A is the 0th variable, and R15 always holds a pointer to the local variables in a given function) Now to compile * , we'll pop two operands off the stack, into RBX and then RAX pop RBX pop RAX So, RAX = ResultOf(Expression.Left) and RBX = ResultOf(Expression.Right) , which means we're ready to generate code to do the first operation ( * ) imul RAX, RBX And in order to follow the rule of pushing our result back onto the stack for another expression, we finish with push RAX Which gives us this (see below) code to evaluate the expression (2 * A) push 1 push 2 push [r15 + (0 * 8)] pop RBX pop RAX add RAX, RBX push RAX Once the CPU finishes the push RAX instruction, the stack will be laid out as so: [1, ResultOf(\"2 * A\")] Which you might notice are the two operands for 1 + (2 * A) , so now all we need to do to compile the + operator is pop RBX pop RAX To load the two operands, and then add RAX, RBX to do the operation, and finally push RAX to store the result. Now we're left with the final generated code of: push 1 ; The result of the token '1' push 2 ; The result of the token '2' push [r15 + (0 * 8)] ; The result of the token 'A' pop RBX ; Right operand, the result of the last expression evaluated ('A' in this case) pop RAX ; Left operand, the result of the 2nd to last expression evaluated ('2' in this case) imul RAX, RBX push RAX ; Stores the result of (Left * Right) as the result of the last expression evaluated pop RBX ; Right operand, result of the last expression evaluated ('2 * A' in this case) pop RAX ; Left operand, result of the 2nd to last expression evaluated ('1' in this case) add RAX, RBX push RAX ; Stores the result of `(Left + Right)` as the result of the last expression evaluated And a quick example with a unary operator instead, 1 + !2 : .Compile(Expression.Left) Generates: push 1 .Compile(Expression.Right) Generates code to evaluate !2 , which in itself runs .Compile(UnaryExpression.Operand) , generating the code: push 2 And then evaluating the operand with pop RAX not RAX push RAX And now we've got both the operands on the stack, so we generate code for + : pop RBX pop RAX add RAX, RBX push RAX Which leaves us with push 1 push 2 pop RAX not RAX push RAX pop RBX pop RAX add RAX, RBX push RAX So, thanks to these expression evaluation rules, all that's needed to add an new operator is to add it to CodeGen , and implement it enough that it will use RAX and RBX as operands, and push a result onto the stack. Now, you might notice that this generates some pretty bad code, with lots of stack usage, which is bad for speed and code size. To get around this, I lied I little bit during these examples. The generated code doesn't actually use the CPU stack, instead it uses the registers [RCX, RDX, R8, R9, R10, R11, R12, R13] as a fake stack, which the compiler will automatically keep track of what parts are being used. This eliminates lots of the extra push and pop -ing, since our 1 + (2 * A) example would be generated as mov RCX, 1 ; Push register stack, store value into new top of stack mov RDX, 2 ; Same as above mov R8, [r15 + (0 * 8)] ; Same as above imul RDX, R8 ; Pop register stack twice, multiply popped registers, store result into the top of stack add RCX, RDX ; Same as above, just with multiplication. Of course, this optimization isn't perfect, and extra instructions are still generated, but this reduces the bloat a lot, and by keeping operands in registers, it also improves speed.","title":"Compiler"},{"location":"how-it-works/#type-checking","text":"Type checking is done as a bit of an afterthought, but the general idea is that each .CompileXXXX method will return the type of the value which it has pushed onto the stack. And by using the returned type, we can check if it is compatible with the types of other components of a given AST node. For example, to compile a binary expression, we have the code: LeftType := this.Compile(Expression.Left) RightType := this.Compile(Expression.Right) And then later on, we have: ResultType := this.Typing.ResultType(LeftType, RightType) And when there is no result type for that combination of operand types, and exception is thrown. For example \"Abc\" * 2.5 Would have LeftType = i8* , and RightType = f64 . Which are two obviously incompatible types. However, if we have two operands that are similar types, but not the exact same type, there can be an implicit cast, for example: 1 * 2.5 Would have LeftType = i8 , and RightType = f64 . However, since both types are numeric, and floating pointer numbers are considered more precise, the compiler would get ResultType = f64 . And to ensure that both operands are actually compatible, and not just theoretically compatible, each .CompileXXXXXExpression will include calls to this.Cast(RightType, ResultType) and this.Cast(LeftType, ResultType) . .Cast takes the current type of the value on top of the stack, and the desired type, and converts them via the .Cast_FirstTypeName_SecondTypeName methods. So, in this case, first 2.5 would be cast to f64 (which requires no extra code to be generated, since it is already that type), and then 1 would be cast to f64 . For casting to/from floating point numbers, the instructions FILD / FSTP and FLD / FISTP instructions are used, which For FILD / FSTP : loads an integer into an FPU register as a floating point number, and then writes that integer back as a floating point number For FLD / FISTP : loads a floating point number into an FPU register, and then writes that float back as an integer The only other casts are integer size conversions, which are done by the CBWE , CWDE , CDQE instructions, aka: Convert byte to word (i8 -> i16) Convert word to double word (i16 -> i32) Convert double word to quad word (i32 -> i64) Type checking is also done for function calls and return values through checking if each parameter is of the correct type while compiling each parameter, and for return types, it is done when compiling return statements.","title":"Type Checking"},{"location":"how-it-works/#strings-and-other-stuff","text":"The compiler handles strings by allocating StrLen(String) + 1 bytes much of stack space for each string, and encodes string literals into 64 bit integers, which when pushed onto the stack, will build the correctly ordered string. Actual references to strings are replaced by references to the hidden local variables __String__Full Text Of The String , which is then set to a pointer into the stack where the string was pushed. So, \"Hello world\" is compiled into a series of instructions like mov rax, 0 push rax mov rax, 217478657420656D push rax mov rax, 6F73207265746E45 push rax (Note, that's not actually \"Hello World\", I just copied that out of a random example .exe ) Parameters are treated exactly the same as locals, and all variables can be addressed using a \"SIB\" (See CodeGen for what that means), which allows getting/setting variables with minimum boilerplate. Function calls are a bit of a mess. Since the register stack uses some of the parameter registers, first the register stack has to be saved, and then the parameter registers have to be 0'd, and finally, the parameters can be compiled and moved into the parameter registers. When a function never has a return statement compiled, the return value is automatically set to 0. This is the only difference for omitting return , since the code to return from a function is automatically generated at the end of a function either way. Signed numbers are the only kind of numbers, unsigned operations require entirely different instructions for operations, which is why I don't plan on adding unsigned types.","title":"Strings And Other Stuff"},{"location":"how-it-works/#codegen","text":"This one will be shorter, I promise. CodeGen is a class which generates the correct bytes for lots of common AMD64 instructions, and automatically handles linking labels and jumps for you. This is done by storing an internal array of bytes, which contains assembled instructions, with objects pushed onto the array when CodeGen does not have enough information at the time to link the given label to an address. Additionally, CodeGen pushes objects for pointers to global variables, and pointers to functions imported from Dll files. CodeGen doesn't actually process these extra objects, but keeps them intact until either the \"second stage\" linkers in PEBuilder or ToAHK can link the code to actual pointers. The backbone of CodeGen is just a few methods: .REX(REXBits) Which will build a \"REX prefix\" for an instruction, which will promote the instruction to use 64 bit registers and data, along with giving it access to the new GPRs R8-R15. .REXOpcode(OpcodeBytes, REXParts) Which will build a REX prefix, and then write an opcode. .REXOpcodeMod(OpcodeBytes, DestRegister, SourceRegister, Options) Which will build a REX prefix, write the opcode, and then write a \"ModRM\" byte, which controls the operands, and operand types of an instruction. .REXOpcodeModSIB(Opcode, Register, SIB, Options) Which will build a REX prefix, opcode, and ModRM byte which uses the SIB addressing mode. SIB stands for (S)cale (I)ndex (B)ase, which allows you to have address calculations like FinalAddress = GetRegisterValue(SIB.Base) + (GetRegisterValue(SIB.Index) * SIB.Scale) , which are very useful for indexing the local table, global table, and import table. .NumberSizeOf(Number) Which returns the minimum number of bits needed to store the given number (used for instruction selection). .SplitIntoBytes32(Number) Which splits a 32 bit number into bytes, and stores it big-endian (like the processor expects). .SplitIntoBytes64(Number) Same as above, but with a 64 bit number. .Link() Which will resolve all labels, and return the partially linked code for a second stage linker.","title":"CodeGen"},{"location":"how-it-works/#pebuilder","text":"A class that handles all the dirty work of building .exe files. Most of the code is spent building the headers, and setting the correct magic numbers. The only interesting bit is how the import address table (IAT) and .reloc (relocation) section is built. The IAT is built with one structure for each Dll that functions are imported from, and 2 parallel arrays which hold the actual import data. The structure holds a pointer to the first array, the number of entries in all of the arrays, a pointer to the Dll name, and a pointer to the 2rd array. Each entry in the 1st and 2nd array is identical until the .exe file is loaded, but before that, an entry considered part of a \"hint-name table\", which is made up of an ordinal value for the imported function, or a pointer to the function's name. I do not bother with ordinal values. Once the loader reads the hint-name table, each entry in the 2nd array is overwritten with a pointer to the function it originally imported, which PEBuilder links code to jump into. The .reloc section handles what should happen when the file can't be loaded at the specified base address, and contains pointers to every location inside of the code which references a static address. So, every use of a global variable, and every use of an import function, gets an entry in the .reloc section. If you're wondering, the default section layout (which you can't change) is: Section Name What it's for .data Holds global variables .text Holds compiled code, and the program entry point .idata Holds the IAT, hint-name table, import file/name strings .reloc Holds the relocation info","title":"PEBuilder"},{"location":"how-it-works/#toahk","text":"A single function, which just dumps a program as a bunch of AHK functions It pretends to be the windows loader via some boilerplate, and pretends to be PEBuilder in the same boilerplate, by linking global pointers and imported function pointers. There's really not much to say about it.","title":"ToAHK"},{"location":"how-to-use-it/","text":"Main Main.ahk contains pretty basic command line interface, which is used to compile Relax programs. Main.exe is simply a compiled (by AHK) version of Main.ahk with the Subsystem header field set to IMAGE_SUBSYSTEM_WINDOWS_CUI instead of the standard IMAGE_SUBSYSTEM_WINDOWS_GUI for AHK files, which allows it to run like another other command line program. Since both Main.ahk and Main.exe function the same, I'll just be referring to them as Main from here on. Note If Main.exe has problems building a program (ex: has no output, doesn't write to output file), it might have been blocked by windows. To solve this, just use Main.ahk , which just opens a new console window when run. Programs A Relax program is described in a few different places, so I won't describe it again, but you should know that the unofficial .rlx file type can be used for Relax source files. This is not official in any way, and Main doesn't even check the extensions. How to use it Main takes the arguments: Name Parameter Meaning -i [InputFile] Read the source code to compile from the given path -o [OutputFile] Write the compiled code to the given path. If this path has the extension .ahk , then the input file will be compiled into AHK functions. Otherwise, a .exe file will be built at the path. --no-confirm N/A Stops a confirmation message and user input being required before [InputFile] is compiled. --no-overwrite-output-file N/A Causes Main to exit when [OutputFile] already exists. (for safety) --fast-exit N/A Skips asking the user to press {Enter} before Main closes. --silent N/A Skips all steps that require user input. --verbose N/A Prints a log of what the compiler is doing. Where [InputFile] and [OutputFile] must both be given. For example, compiling Examples\\SimpleConsoleProgram.rlx with no extra confirmation message into a.exe with verbose mode enabled would be: Main.exe --no-confirm --verbose -i Examples\\SimpleConsoleProgram.rlx -o a.exe If there are any errors while compiling, they will be printed, and the compiler will abort.","title":"How to use it"},{"location":"how-to-use-it/#main","text":"Main.ahk contains pretty basic command line interface, which is used to compile Relax programs. Main.exe is simply a compiled (by AHK) version of Main.ahk with the Subsystem header field set to IMAGE_SUBSYSTEM_WINDOWS_CUI instead of the standard IMAGE_SUBSYSTEM_WINDOWS_GUI for AHK files, which allows it to run like another other command line program. Since both Main.ahk and Main.exe function the same, I'll just be referring to them as Main from here on.","title":"Main"},{"location":"how-to-use-it/#note","text":"If Main.exe has problems building a program (ex: has no output, doesn't write to output file), it might have been blocked by windows. To solve this, just use Main.ahk , which just opens a new console window when run.","title":"Note"},{"location":"how-to-use-it/#programs","text":"A Relax program is described in a few different places, so I won't describe it again, but you should know that the unofficial .rlx file type can be used for Relax source files. This is not official in any way, and Main doesn't even check the extensions.","title":"Programs"},{"location":"how-to-use-it/#how-to-use-it","text":"Main takes the arguments: Name Parameter Meaning -i [InputFile] Read the source code to compile from the given path -o [OutputFile] Write the compiled code to the given path. If this path has the extension .ahk , then the input file will be compiled into AHK functions. Otherwise, a .exe file will be built at the path. --no-confirm N/A Stops a confirmation message and user input being required before [InputFile] is compiled. --no-overwrite-output-file N/A Causes Main to exit when [OutputFile] already exists. (for safety) --fast-exit N/A Skips asking the user to press {Enter} before Main closes. --silent N/A Skips all steps that require user input. --verbose N/A Prints a log of what the compiler is doing. Where [InputFile] and [OutputFile] must both be given. For example, compiling Examples\\SimpleConsoleProgram.rlx with no extra confirmation message into a.exe with verbose mode enabled would be: Main.exe --no-confirm --verbose -i Examples\\SimpleConsoleProgram.rlx -o a.exe If there are any errors while compiling, they will be printed, and the compiler will abort.","title":"How to use it"},{"location":"module-console/","text":"The Console Module Top 10 reasons I hate the Windows Console API. DllImports Imported Function Name Imported Function Source GetStdHandle GetStdHandle, Kernel32 WriteConsole WriteConsoleW, Kernel32 SetConsoleTextAttribute SetConsoleTextAttribute, Kernel32 ReadConsole ReadConsoleW, Kernel32 Globals Full Global Name Default Value i64 Console:STDIN Console:GetStdHandle(-10) i64 Console:STDOUT Console:GetStdHandle(-11) i64 Console:STDERR Console:GetStdHandle(-12) i16 Console:Bright 0x08 i16 Console:Red 0x04 i16 Console:Green 0x02 i16 Console:Blue 0x01 i16 Console:White 0x0F i16 Console:Black 0x00 Functions Function Name Return Type Parameter List Description AWrite i32 i8* AString Converts AString to a wide string, and prints it with Console:Write . AWriteLine i32 i8* AString Converts AString to a wide string, and prints it with Console:WriteLine . IWrite i32 i64 Number Converts Number to a wide string with String:IToW and prints it with Console:Write . IWriteLine i32 i64 Number Converts Number to a wide string with String:IToW and prints it with Console:WriteLine . Write i32 i16* WString Prints WString to Console:STDOUT using WriteConsole . WriteLine i32 i16* WString Prints WString using Console:Write and then \\r\\n using Console:Write . SetColor void i8 Foreground , i8 Background Changes the console text colors using SetConsoleTextAttribute . ResetColors void Resets the console text colors to white/black using Console:SetColor . TextColor void i8 Foreground Sets the console foreground color to Foreground and the background to black with Console:SetColor . ReadLine i16* Waits for the user to enter a line of input and press enter using ReadConsole . Notes If you are using the Console module while compiling to AHK , you will need to include the following snippet (in out.ahk ) to create a console window, and have Console get the correct handles to STD(IN|OUT|ERR). DllCall(\"AllocConsole\") __RunTime__SetGlobals() Console is a relatively high-level module, and manages a lot of things for you. For example, IWriteXXXX and AWriteXXXX both free any intermediate buffers allocated for you, and SetColor builds the correct structure for color settings for you. ReadLine handles the allocation and extension of a buffer for console input, and calling ReadConsole in a loop to read all input. Usage Impact Console imports both String and Memory , which results in ~8 KB of extra code being generated.","title":"The Console Module"},{"location":"module-console/#the-console-module","text":"Top 10 reasons I hate the Windows Console API.","title":"The Console Module"},{"location":"module-console/#dllimports","text":"Imported Function Name Imported Function Source GetStdHandle GetStdHandle, Kernel32 WriteConsole WriteConsoleW, Kernel32 SetConsoleTextAttribute SetConsoleTextAttribute, Kernel32 ReadConsole ReadConsoleW, Kernel32","title":"DllImports"},{"location":"module-console/#globals","text":"Full Global Name Default Value i64 Console:STDIN Console:GetStdHandle(-10) i64 Console:STDOUT Console:GetStdHandle(-11) i64 Console:STDERR Console:GetStdHandle(-12) i16 Console:Bright 0x08 i16 Console:Red 0x04 i16 Console:Green 0x02 i16 Console:Blue 0x01 i16 Console:White 0x0F i16 Console:Black 0x00","title":"Globals"},{"location":"module-console/#functions","text":"Function Name Return Type Parameter List Description AWrite i32 i8* AString Converts AString to a wide string, and prints it with Console:Write . AWriteLine i32 i8* AString Converts AString to a wide string, and prints it with Console:WriteLine . IWrite i32 i64 Number Converts Number to a wide string with String:IToW and prints it with Console:Write . IWriteLine i32 i64 Number Converts Number to a wide string with String:IToW and prints it with Console:WriteLine . Write i32 i16* WString Prints WString to Console:STDOUT using WriteConsole . WriteLine i32 i16* WString Prints WString using Console:Write and then \\r\\n using Console:Write . SetColor void i8 Foreground , i8 Background Changes the console text colors using SetConsoleTextAttribute . ResetColors void Resets the console text colors to white/black using Console:SetColor . TextColor void i8 Foreground Sets the console foreground color to Foreground and the background to black with Console:SetColor . ReadLine i16* Waits for the user to enter a line of input and press enter using ReadConsole .","title":"Functions"},{"location":"module-console/#notes","text":"If you are using the Console module while compiling to AHK , you will need to include the following snippet (in out.ahk ) to create a console window, and have Console get the correct handles to STD(IN|OUT|ERR). DllCall(\"AllocConsole\") __RunTime__SetGlobals() Console is a relatively high-level module, and manages a lot of things for you. For example, IWriteXXXX and AWriteXXXX both free any intermediate buffers allocated for you, and SetColor builds the correct structure for color settings for you. ReadLine handles the allocation and extension of a buffer for console input, and calling ReadConsole in a loop to read all input.","title":"Notes"},{"location":"module-console/#usage-impact","text":"Console imports both String and Memory , which results in ~8 KB of extra code being generated.","title":"Usage Impact"},{"location":"module-memory/","text":"The Memory Module You'll never guess what this one does. DllImports Imported Function Name Imported Function Source GetProcessHeap GetProcessHeap, Kernel32 HeapAlloc HeapAlloc, Kernel32 HeapReAlloc HeapReAlloc, Kernel32 HeapFree HeapFree, Kernel32 Globals Full Global Name Default Value i64 Memory:ProcessHeap Memory:GetProcessHeap() i32 Memory:HEAP_ZERO_MEMORY 0x00000008 Functions Function Name Return Type Parameter List Description Alloc void* i64 Size Allocates Size bytes of memory on the heap, and returns a pointer to the allocated memory ReAlloc void* void* Memory , i64 NewSize Resizes Memory to NewSize and returns the new pointer to the memory Free i8 void* Memory Frees Memory Usage Impact Memory does not import any other modules, and only takes ~150 bytes of the output file for imports + generated code. Memory only exists so GetProcessHeap only needs to be called once.","title":"The Memory Module"},{"location":"module-memory/#the-memory-module","text":"You'll never guess what this one does.","title":"The Memory Module"},{"location":"module-memory/#dllimports","text":"Imported Function Name Imported Function Source GetProcessHeap GetProcessHeap, Kernel32 HeapAlloc HeapAlloc, Kernel32 HeapReAlloc HeapReAlloc, Kernel32 HeapFree HeapFree, Kernel32","title":"DllImports"},{"location":"module-memory/#globals","text":"Full Global Name Default Value i64 Memory:ProcessHeap Memory:GetProcessHeap() i32 Memory:HEAP_ZERO_MEMORY 0x00000008","title":"Globals"},{"location":"module-memory/#functions","text":"Function Name Return Type Parameter List Description Alloc void* i64 Size Allocates Size bytes of memory on the heap, and returns a pointer to the allocated memory ReAlloc void* void* Memory , i64 NewSize Resizes Memory to NewSize and returns the new pointer to the memory Free i8 void* Memory Frees Memory","title":"Functions"},{"location":"module-memory/#usage-impact","text":"Memory does not import any other modules, and only takes ~150 bytes of the output file for imports + generated code. Memory only exists so GetProcessHeap only needs to be called once.","title":"Usage Impact"},{"location":"module-string/","text":"The String Module Lots and lots of unsafe code. DllImports None Globals None Functions Function Name Return Type Parameter List Description ALen i32 i8* AString Counts how long the given ASCII string is by finding the null-terminator of the string. WLen i32 i16* WString Counts how long the given UTF-16 string is by finding the null-terminator of the string. WAEquals i8 i16* WString , i8* AString Compares the two given strings using String:WEquals after converting AString to a wide string. WEquals i8 i16* WStringOne , i16* WStringTwo Trims \\r\\n from both strings using String:WTrimNewline , and compares the two using String:WEqual . WEqual i8 i16* WStringOne , i16* WStringTwo Compares the two strings character by character, and returns 1 if the strings are equal. WTrimNewline i16* i16* WString Removes \\r\\n from the last two characters of the string, if they are there. AReverse i8* i8* AString Reverses AString character by character, leaving the null-terminator in place. WToI i64 i16* WString , i8* Success Tries to read an integer from WString , sets Success to 1 when an integer was read, and returns it. WIsNumeric i8 i16 Character Returns if the character is in the range of '0'->'9'. IToA i8* i64 Number Converts Number to an ASCII string, including '-' if Number is negative. IToW i16* i64 Number Calls String:IToA , converts the result to a wide string with String:AToW and returns it. AToW i16* i8* AString Converts AString to a wide string, and returns the new wide string. Notes None of these functions take string lengths, mostly because memory safety has been bleeding out on the floor since the start of this project. They work as long as you don't break things. Also, they don't take an output buffer as parameters, mostly because that would just shift the blame of who needs to allocate memory. If a function returns a string type, you are expected to free it with Memory:Free . Usage Impact String imports the Memory module, which alone is not very impactful. However, since String is entirely implemented in Relax, and many of the String: functions depend on each other, the module generates upwards of 5 KB of code.","title":"The String Module"},{"location":"module-string/#the-string-module","text":"Lots and lots of unsafe code.","title":"The String Module"},{"location":"module-string/#dllimports","text":"None","title":"DllImports"},{"location":"module-string/#globals","text":"None","title":"Globals"},{"location":"module-string/#functions","text":"Function Name Return Type Parameter List Description ALen i32 i8* AString Counts how long the given ASCII string is by finding the null-terminator of the string. WLen i32 i16* WString Counts how long the given UTF-16 string is by finding the null-terminator of the string. WAEquals i8 i16* WString , i8* AString Compares the two given strings using String:WEquals after converting AString to a wide string. WEquals i8 i16* WStringOne , i16* WStringTwo Trims \\r\\n from both strings using String:WTrimNewline , and compares the two using String:WEqual . WEqual i8 i16* WStringOne , i16* WStringTwo Compares the two strings character by character, and returns 1 if the strings are equal. WTrimNewline i16* i16* WString Removes \\r\\n from the last two characters of the string, if they are there. AReverse i8* i8* AString Reverses AString character by character, leaving the null-terminator in place. WToI i64 i16* WString , i8* Success Tries to read an integer from WString , sets Success to 1 when an integer was read, and returns it. WIsNumeric i8 i16 Character Returns if the character is in the range of '0'->'9'. IToA i8* i64 Number Converts Number to an ASCII string, including '-' if Number is negative. IToW i16* i64 Number Calls String:IToA , converts the result to a wide string with String:AToW and returns it. AToW i16* i8* AString Converts AString to a wide string, and returns the new wide string.","title":"Functions"},{"location":"module-string/#notes","text":"None of these functions take string lengths, mostly because memory safety has been bleeding out on the floor since the start of this project. They work as long as you don't break things. Also, they don't take an output buffer as parameters, mostly because that would just shift the blame of who needs to allocate memory. If a function returns a string type, you are expected to free it with Memory:Free .","title":"Notes"},{"location":"module-string/#usage-impact","text":"String imports the Memory module, which alone is not very impactful. However, since String is entirely implemented in Relax, and many of the String: functions depend on each other, the module generates upwards of 5 KB of code.","title":"Usage Impact"},{"location":"tutorial/","text":"So you want to write a program, eh? For if you don't know C, or have problems guessing syntax from examples See the basic tutorial before reading this. And since the basic tutorial is a mess, don't expect much more from this one. The goal: Write a nice hello world program So, we'll start with the Main function, which is automatically run when you run the output .exe file. Main always has the same definition: define i32 Main(i64 ArgC, void* ArgV) { } The parameters and return type do not matter for this tutorial, but it's worth knowing that: The i32 return value is used as the program's exit code. ArgC is the number of command line args. ArgV is an array of i16* values, which are the command line args as strings. First off, just know that a \"module\" is just a group of functions which are all related. Modules can't be defined, but a few come pre-made. In order to to actually use a module, we need to Import it first, and so for interacting with the console, we'll need the Console module. So our code is now: Import Console define i32 Main(i64 ArgC, void* ArgV) { } Now, we need to get to the printing. First we'll store the text we want to print into the variable Message , which will be a i8* . This is because a string of text is stored as a list of i8 values. Import Console define i32 Main(i64 ArgC, void* ArgV) { i8* Message := \"Hello world!\" } Now, we'll use the Console module's function AWrite to write Message to the console. The AWrite name stands for ASCII Write because i8* text is stored as ASCII characters. In order to call AWrite , we need to prefix it with the module name, and a : character, like: Console:AWrite() Now we'll just add that, and get: Import Console define i32 Main(i64 ArgC, void* ArgV) { i8* Message := \"Hello world!\" Console:AWrite(Message) } Congrats, you just wrote hello world. You can now run out.exe and see the result. Summary So, you know the format for defining functions, declaring variables, along with setting variables, which is good. And just in case you didn't quite catch those, here they are in a list: Function definitions follow the format define ReturnType Name(ParameterList) {} Parameter lists follow the format ParameterType ParameterName, ParameterType ParameterName which can be repeated as much as you like. Function bodies are just lists of lines, including more function calls, variable declarations, and statements like if , for , and return Variable declarations follow the format TypeName VariableName with the optional := Value . Function calls follow the format Name(Parameters) where Parameters is a list of comma-seperated values. Function calls into modules are prefixed with ModuleName: the Main function is always declared as define i32 Main(i64 ArgC, void* ArgV) and is always the first function called. One last thing Sorry if this wasn't the most helpful tutorial, I'm not very good at writing them.","title":"Tutorial"},{"location":"tutorial/#so-you-want-to-write-a-program-eh","text":"","title":"So you want to write a program, eh?"},{"location":"tutorial/#for-if-you-dont-know-c-or-have-problems-guessing-syntax-from-examples","text":"See the basic tutorial before reading this. And since the basic tutorial is a mess, don't expect much more from this one.","title":"For if you don't know C, or have problems guessing syntax from examples"},{"location":"tutorial/#the-goal-write-a-nice-hello-world-program","text":"So, we'll start with the Main function, which is automatically run when you run the output .exe file. Main always has the same definition: define i32 Main(i64 ArgC, void* ArgV) { } The parameters and return type do not matter for this tutorial, but it's worth knowing that: The i32 return value is used as the program's exit code. ArgC is the number of command line args. ArgV is an array of i16* values, which are the command line args as strings. First off, just know that a \"module\" is just a group of functions which are all related. Modules can't be defined, but a few come pre-made. In order to to actually use a module, we need to Import it first, and so for interacting with the console, we'll need the Console module. So our code is now: Import Console define i32 Main(i64 ArgC, void* ArgV) { } Now, we need to get to the printing. First we'll store the text we want to print into the variable Message , which will be a i8* . This is because a string of text is stored as a list of i8 values. Import Console define i32 Main(i64 ArgC, void* ArgV) { i8* Message := \"Hello world!\" } Now, we'll use the Console module's function AWrite to write Message to the console. The AWrite name stands for ASCII Write because i8* text is stored as ASCII characters. In order to call AWrite , we need to prefix it with the module name, and a : character, like: Console:AWrite() Now we'll just add that, and get: Import Console define i32 Main(i64 ArgC, void* ArgV) { i8* Message := \"Hello world!\" Console:AWrite(Message) } Congrats, you just wrote hello world. You can now run out.exe and see the result.","title":"The goal: Write a nice hello world program"},{"location":"tutorial/#summary","text":"So, you know the format for defining functions, declaring variables, along with setting variables, which is good. And just in case you didn't quite catch those, here they are in a list: Function definitions follow the format define ReturnType Name(ParameterList) {} Parameter lists follow the format ParameterType ParameterName, ParameterType ParameterName which can be repeated as much as you like. Function bodies are just lists of lines, including more function calls, variable declarations, and statements like if , for , and return Variable declarations follow the format TypeName VariableName with the optional := Value . Function calls follow the format Name(Parameters) where Parameters is a list of comma-seperated values. Function calls into modules are prefixed with ModuleName: the Main function is always declared as define i32 Main(i64 ArgC, void* ArgV) and is always the first function called.","title":"Summary"},{"location":"tutorial/#one-last-thing","text":"Sorry if this wasn't the most helpful tutorial, I'm not very good at writing them.","title":"One last thing"}]}