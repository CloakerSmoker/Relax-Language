# The compiler

## Main.rlx

[Main](./Main.rlx) contains the `Main` function for the compiler, and the `Main` function does the following:
* Reads the command line arguments to find the input/output files
* Checks for the `--elf` and `--pe` flags to control the format of the output binary.
* Checks for the `--function-bytes` flag to decide if function offset/size info should be dumped.
* Ensures that both an input, and output file are specified.
* Reads the input file, creates a `TokenizerState` for the source, and calls `ParserStart` to parse the input file.
* Passes the parser output to `CompilerStart`, which compiles the code, and builds the output file.

Additionally, `Main.rlx` provides the `OpenAndRead` function, which will try to open and read a source file, with potential errors handled.

## Lexer.rlx

[Lexer](./Lexer.rlx) contains the Tokenizer (I just realized how dumb that sounds, but I am too lazy to rename the file), along with the `Token` and `TokenizerState` structs.

Additionally, `Lexer` defines the `TOKEN_TYPE_*`, `OPERATOR_*`, `PUNCTUATION_*`, `KEYWORD_*` globals, which are used by the parser to handle any specific token without having to do text comparisons.

---

The actual tokenizing happens in the `GetNextToken` function, which will translate the next character(s) into a token type/value pair, then call `MakeToken` to build a new `Token*` for the pair.

`MakeToken` will also stores some context inside of the new `Token*` (such as line number and source file path), which is used to display error messages.

In order to support backtracking, the `TokenizerState` struct contains an array of all tokens, which is indexed separately from the source file. This allows for the `TokenIndex` to be decremented without the tokenizer having to re-tokenize any given code.

---

`Lexer` also contains the `Error` function, which takes a `Token*` which is to blame for the `i8*` error message. This function is used throughout the compiler to as the most basic error reporting.

Other functions such as `ASTError` (from the parser) are used whenever possible, as `Error` shows no context around the error.

## Parser.rlx

[The parser](./Parser.rlx) uses the [tokenizer](#Lexer.rlx) to extract tokens from the source code, which it then parses via recursive descent.

The parser stores state in the `ParserState` struct, which contains a map of defined functions and globals, along with the default types.

---

Inside of the parser, code is represented via the `ASTNode` struct, which consists of a `Type:Value` pair much like the `Token` struct.

The AST node types are defined as `NODE_TYPE_*`, and each have an accompanying field inside of the backing `ASTNode` struct.

For example, the `NODE_TYPE_BINARY` type means that `SomeNode->BinaryNode` is set to a pointer to a `BinaryExpression` struct.

And the `BinaryExpression` struct contains two `ASTNode*` fields for the left and right operands, which can then themselves be more `BinaryExpression` nodes.

This nesting of `ASTNode*` structs is capable of representing any program, and is the only type of intermediate representation the compiler uses.

---

Type checking is also done inside of the parser, as an `ASTNode` is built, operand types are checked for compatibility and used to determine the type of the new node.

Then, the next node being built would use the result type of the child node for its own type checking.

---

Some operators are also interpreted inside of the parser, such as `#Type` or `A As b`, since `#` returns a constant number, and `As` is just an instruction to change the type of an expression.

## Compiler.rlx

The compiler walks the `ASTNode`s generated by the parser for each function, and emits code which is functionally equivalent to the `ASTNode` that is being walked. 

Jumps/calls are linked together via a basic label system, with each function getting a separate label that it should be called by. 
Additionally, `if`/`loop`/`while`/`for` statements all use temporary label along with conditional jumps to generate flow control.

Instructions are actually emitted by:

## CodeGen.rlx

CodeGen contains lots and lots of functions which will generate various x86_64 instructions, and that's pretty much it. The compiler calls into CodeGen to actually generate the output code.

## (ELF|PE)Builder.rlx

These files are for building ELF (Linux) or PE (Windows) executable files containing the code generated by `Compiler.rlx` and `CodeGen.rlx`.

Neither supports any wild features, with the bare minimum feature set being: hold the output code, have space for globals. 

## End
And that's it. This hasn't been the best explanation, but that's what the files do. 