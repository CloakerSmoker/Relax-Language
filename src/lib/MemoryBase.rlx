define void MoveMemory(void* RawTo, void* RawFrom, i32 Size) {
	i8* To := RawTo As i8*
	i8* From := RawFrom As i8*
	
	i32 Index := 0
	
	if (To < From) {
		for (Index := 0, Index < Size, Index += 1) {
			To[Index] := From[Index]
		}
	}
	else {
		for (Index := Size - 1, Index >= 0, Index -= 1) {
			To[Index] := From[Index]
		}
	}
}

define void MoveMemory(void* RawTo, void* RawFrom, i64 Size) {
	MoveMemory(RawTo, RawFrom, Size As i32)
}

define i8 CompareMemory(void* RawLeft, void* RawRight, i32 Size) {
	i8* Left := RawLeft
	i8* Right := RawRight
	
	for (i32 Index := 0, Index < Size, Index++) {
		if (Left[Index] != Right[Index]) {
			return false
		}
	}
	
	return true
}

define void SetMemory(void* RawTarget, i32 Count, i8 Value) {
	i8* Target := RawTarget As i8*
	
	for (i32 Index := 0, Index < Count, Index++) {
		Target[Index] := Value
	}
}
define void SetMemory(void* RawTarget, i32 Count, i16 Value) {
	i16* Target := RawTarget As i16*
	
	for (i32 Index := 0, Index < Count, Index++) {
		Target[Index] := Value
	}
}
define void SetMemory(void* RawTarget, i32 Count, i32 Value) {
	i32* Target := RawTarget As i32*
	
	for (i32 Index := 0, Index < Count, Index++) {
		Target[Index] := Value
	}
}
define void SetMemory(void* RawTarget, i32 Count, i64 Value) {
	i64* Target := RawTarget As i64*
	
	for (i32 Index := 0, Index < Count, Index++) {
		Target[Index] := Value
	}
}

define void FastSetMemory8(void* Memory, i64 Value, i64 Count) asm {
	mov, rax, rsi
	mov, rcx, rdx

	cld
	rep stosb

	ret
}
define void FastSetMemory64(void* Memory, i64 Value, i64 Count) asm {
	mov, rax, rsi
	mov, rcx, rdx

	cld
	rep stosq

	ret
}
define void FastZeroMemory(void* Memory, i64 Size) {
	i64 Offset := Size & ~0x7
	i64 Eights := Offset >> 3
	i64 Ones := Size & 0x7

	FastSetMemory64(Memory, 0, Eights)
	FastSetMemory8(Memory + Offset, 0, Ones)
}
define void FastMoveMemory(void* To, void* From, i64 Size) asm {
	mov, rcx, rdx

	cmp, rdi, rsi
	jlt, MoveDown

	dec, rdx
	add, rdi, rdx
	add, rsi, rdx

	std
	rep movsb
	cld

	ret

MoveDown:
	cld
	rep movsb

	ret
}
